<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on μβ</title>
    <link>https://mbesancon.github.io/post/</link>
    <description>Recent content in Posts on μβ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Mathieu Besançon</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 -0500</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Solving the group expenses headache with graphs</title>
      <link>https://mbesancon.github.io/post/2017-09-11-graph-theory-expenses-management/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2017-09-11-graph-theory-expenses-management/</guid>
      <description>

&lt;p&gt;With the end-of-year celebrations, we all had some expenses to manage,
some of them shared with friends, and we all have this eternal problem
of splitting them fairly.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Les bons comptes font les bons amis.&lt;/em&gt;
French wisdom&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Applications like &lt;a href=&#34;https://tricount.com/&#34; target=&#34;_blank&#34;&gt;Tricount&lt;/a&gt; or
&lt;a href=&#34;https://www.splitwise.com/&#34; target=&#34;_blank&#34;&gt;Splitwise&lt;/a&gt; became famous precisely by
solving this problem for you: just enter the expenses one by one, with who
owes whom and you&amp;rsquo;ll get the simplest transactions to balance the amounts at
the end.&lt;/p&gt;

&lt;p&gt;In this post, we&amp;rsquo;ll model the expense balancing problem from a graph
perspective and see how to come up with a solution using Julia and the
JuliaGraphs ecosystem [1].&lt;/p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;We will use the awesome GraphCoin as a currency in this post, noted GPHC to
be sure no one feels hurt.&lt;/p&gt;

&lt;/div&gt;


&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-expenses-model&#34;&gt;The expenses model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reducing-expenses&#34;&gt;Reducing expenses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#breaking-strongly-connected-components&#34;&gt;Breaking strongly connected components&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expenses-as-a-flow-problem&#34;&gt;Expenses as a flow problem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#computing-net-owed-amount-per-user&#34;&gt;Computing net owed amount per user&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#building-the-graph-and-the-corresponding-flow-problem&#34;&gt;Building the graph and the corresponding flow problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#solving-the-flow-problem&#34;&gt;Solving the flow problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trying-out-our-solution&#34;&gt;Trying out our solution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion-perspective-and-note-on-gphc&#34;&gt;Conclusion, perspective and note on GPHC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;h2 id=&#34;the-expenses-model&#34;&gt;The expenses model&lt;/h2&gt;

&lt;p&gt;Say that we have $n$ users involved in the expenses. An expense
$\delta$ is defined by an amount spent $\sigma$, the user who paid the
expense $p$ and a non-empty set of users who are accountable for
this expense $a$.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$\delta = (\sigma, p, a)$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The total of all expenses $\Sigma$ can be though of as: for any two users $u_i$ and $u_j$,
the total amount that $u_i$ spent for $u_j$. So the expenses are a vector of
triplets &lt;em&gt;(paid by, paid for, amount)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;As an example, if I went out for
pizza with Joe and paid 8GPHC for the two of us, the expense is modeled as:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$\delta = (\sigma: 8GPHC, p: Mathieu, a: [Mathieu, Joe])$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now considering I don&amp;rsquo;t keep track of money I owe myself, the sum of all expenses
is the vector composed of one triplet:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$\Sigma = [(Mathieu, Joe, \frac{8}{2} = 4)]$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In Julia, the expense information can be translated to a structure:
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;User &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;
GraphCoin &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float16&lt;/span&gt;
struct Expense
    payer&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;User
    amount&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;GraphCoin
    users&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Set&lt;/span&gt;{User}
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;h2 id=&#34;reducing-expenses&#34;&gt;Reducing expenses&lt;/h2&gt;

&lt;p&gt;Now that we have a full representation of the expenses,
the purpose of balancing is to find a vector of transactions which cancels out
the expenses. A naive approach would be to use the transposed expense matrix
as a transaction matrix. If $u_i$ paid $\Sigma_{i,j}$ for $u_j$,
then $u_j$ paying back that exact amount to $u_i$ will solve the problem.
So we need in the worst case as many transactions after the trip as
$|u| \cdot (|u| - 1)$. For 5 users, that&amp;rsquo;s already 20 transactions,
how can we improve it?&lt;/p&gt;

&lt;h2 id=&#34;breaking-strongly-connected-components&#34;&gt;Breaking strongly connected components&lt;/h2&gt;

&lt;p&gt;Suppose that I paid the pizza slice to Joe for 4GPHC, but he bought me an ice
cream for 2GPHC the day after. In the naive models, we would have two
transactions after the trip: he give me 4GPHC and I would give him 2GPHC. That
does not make any sense, he should simply pay the difference between what he
owes me and what I owe him. For any pair of users, there should only be
at most one transaction from the most in debt to the other, this result in the
worst case of $\frac{|u| \cdot (|u| - 1)}{2}$ transactions, so 10 transactions
for 5 people.&lt;/p&gt;

&lt;p&gt;Now imagine I still paid 4GPHC for Joe, who paid 2GPHC for Marie, who paid 4GPHC
for me. In graph terminology, this is called a
&lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Strongly_connected_component&#34; target=&#34;_blank&#34;&gt;strongly connected component&lt;/a&gt;&lt;/em&gt;.
The point here is that transactions will flow from one user to the next one,
and back to the first.&lt;/p&gt;

&lt;p&gt;If there is a cycle, we can find the minimal due sum within it. In our 3-people
case, it is 2GPHC. That&amp;rsquo;s the amount which is just moving from hand to hand and
back at the origin: it can be forgotten. This yields a new net debt:
I paid 2GPHC for Joe, Marie paid 2GPHC for me. We reduced the number of
transactions and the amount due thanks to this cycle reduction.&lt;/p&gt;

&lt;h2 id=&#34;expenses-as-a-flow-problem&#34;&gt;Expenses as a flow problem&lt;/h2&gt;

&lt;p&gt;To simplify the problem, we can notice we don&amp;rsquo;t actually care about who paid
whom for what, a fair reimbursement plan only requires two conditions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;All people who are owed some money are given at least that amount&lt;/li&gt;
&lt;li&gt;People who owe money don&amp;rsquo;t pay more than the net amount they ought to pay&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We can define a directed flow network with users split in two sets of vertices,
depending on whether they owe or are owed money. We call these two sets $V_1$
and $V_2$ respectively.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There is an edge from any node of $V_1$ to any node of $V_2$.&lt;/li&gt;
&lt;li&gt;We define a &lt;em&gt;source&lt;/em&gt; noted $s$ connected to all vertices in $V_1$, the edge
from $s$ to any node of $V_1$ has a capacity equal to what they owe.&lt;/li&gt;
&lt;li&gt;We define a &lt;em&gt;sink&lt;/em&gt; noted $t$ to which all vertices in $V_2$ connect, with
infinite capacity and a demand (the minimal flow that has to pass through) equal
to what they are owed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this model, GraphCoins will flow from user owing money to users who are
owed money, see &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_flow_problem&#34; target=&#34;_blank&#34;&gt;Wikipedia description of the flow problem&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;computing-net-owed-amount-per-user&#34;&gt;Computing net owed amount per user&lt;/h3&gt;

&lt;p&gt;Given a vector of expenses, we should be able to build the matrix holding what
is owed in net from a user to another:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300&#34;&gt;    Builds the matrix of net owed GraphCoins&lt;/span&gt;
&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt; compute_net_owing(expenses&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Vector&lt;/span&gt;{Expense}, nusers&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;)
    owing_matrix &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; zeros(GraphCoin, nusers, nusers)
    &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# row owes to column&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; expense &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; expenses
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; user &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; expense&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;users
            &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; user &lt;span style=&#34;color: #555555&#34;&gt;!=&lt;/span&gt; expense&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;payer
                owing_matrix[user,expense&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;payer] &lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt; expense&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;amount &lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt; length(expense&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;users)
            &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# compute net owed amount&lt;/span&gt;
    net_owing &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; zeros(GraphCoin, nusers, nusers)    
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;nusers&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; i&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;nusers
            &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; owing_matrix[i,j] &lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;&lt;/span&gt; owing_matrix[j,i]
                net_owing[i,j] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; owing_matrix[i,j] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; owing_matrix[j,i]
            &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;elseif&lt;/span&gt; owing_matrix[i,j] &lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;&lt;/span&gt; owing_matrix[j,i]
                net_owing[j,i] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; owing_matrix[j,i] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; owing_matrix[i,j]
            &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; net_owing&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Matrix&lt;/span&gt;{GraphCoin}
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;From that matrix, we should determine the net amount any user owes or is owed:
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300&#34;&gt;    What is owed to a given user (negative if user owes money)&lt;/span&gt;
&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt; net_owed_user(net_owing&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Matrix&lt;/span&gt;{GraphCoin})
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; (sum(net_owing,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; sum(net_owing,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;))[&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;sum&lt;/code&gt; function used with &lt;code&gt;1&lt;/code&gt; or &lt;code&gt;2&lt;/code&gt; sums a matrix over its rows, columns
respectively. This computes a difference between what a user is owed and what
they owe.&lt;/p&gt;

&lt;h3 id=&#34;building-the-graph-and-the-corresponding-flow-problem&#34;&gt;Building the graph and the corresponding flow problem&lt;/h3&gt;

&lt;p&gt;A flow problem is determined by the directed graph (nodes and directed edges),
the minimal flow for any edge, a maximal flow or capacity for any edge and a
cost of having a certain flow going through each edge.&lt;/p&gt;

&lt;p&gt;First, we need to import LightGraphs, the core package of the JuliaGraph
ecosystem containing essential types.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import LightGraphs; const lg = LightGraphs
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that I use explicit package import (not &lt;code&gt;using&lt;/code&gt;), an habit I
kept from using Python and that I consider more readable than importing
the whole package into the namespace. &lt;code&gt;lg&lt;/code&gt; has become my usual name for the
LightGraphs package.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt; build_graph(net_owing&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Matrix&lt;/span&gt;{GraphCoin})
    nusers &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; size(net_owing,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;)
    g &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; lg&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;DiGraph(nusers &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
    source &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; nusers &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
    sink &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; nusers &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;
    net_user &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; net_owed_user(net_owing)
    v1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [idx &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;nusers &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; net_user[idx] &lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]
    v2 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [idx &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; idx &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;nusers &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; net_user[idx] &lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]
    capacity &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; zeros(GraphCoin, nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
    demand &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; zeros(GraphCoin, nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
    maxcap &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; sum(net_owing)
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; u1 &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; v1
        lg&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;add_edge!(g,source,u1)
        capacity[source,u1] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;net_user[u1]
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; u2 &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; v2
            lg&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;add_edge!(g,u1,u2)
            capacity[u1,u2] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; maxcap
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; u2 &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; v2
        lg&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;add_edge!(g,u2,sink)
        capacity[u2,sink] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; maxcap
        demand[u2,sink] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; net_user[u2]
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    (g, capacity, demand)
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This function builds our graph structure and all informations we need attached.&lt;/p&gt;

&lt;h3 id=&#34;solving-the-flow-problem&#34;&gt;Solving the flow problem&lt;/h3&gt;

&lt;p&gt;Now that the components are set, we can solve the problem using another
component of the JuliaGraphs ecosystem specialized for flow problems:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using LightGraphsFlows: mincost_flow
using Clp: ClpSolver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We also need a Linear Programming solver to pass to the flow solver, all we
have to do is bundle the pieces together:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt; solve_expense(expenses&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Vector&lt;/span&gt;{Expense}, nusers&lt;span style=&#34;color: #555555&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;)
    (g, capacity, demand) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; build_graph(compute_net_owing(expenses, nusers))
    flow &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; mincost_flow(g, capacity, demand, ones(nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;), ClpSolver(), nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;, nusers&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; flow[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We truncate the &lt;code&gt;flow&lt;/code&gt; matrix because we are only interested in what users
are paying each other, not in the flows from and to the source and sink.&lt;/p&gt;

&lt;h3 id=&#34;trying-out-our-solution&#34;&gt;Trying out our solution&lt;/h3&gt;

&lt;p&gt;Now that all functions are set, we can use it on any expense problem:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;expenses &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [
    Expense(&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Set&lt;/span&gt;([&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])),
    Expense(&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;24&lt;/span&gt;, &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Set&lt;/span&gt;([&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;])),
    Expense(&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Set&lt;/span&gt;([&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;]))
]
solve_expense(expenses, &lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;3×3 Array{Float64,2}:
  0.0  0.0  0.0
 18.0  0.0  0.0
  3.0  0.0  0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the result, each row pays to each column and voilà! Our three users don&amp;rsquo;t
have to feel the tension of unpaid debts anymore.&lt;/p&gt;

&lt;h2 id=&#34;conclusion-perspective-and-note-on-gphc&#34;&gt;Conclusion, perspective and note on GPHC&lt;/h2&gt;

&lt;p&gt;We managed to model our specific problem using &lt;em&gt;LightGraphs.jl&lt;/em&gt; and the
associated flow package pretty easily. I have to admit being biased since
I contributed to the JuliaGraphs ecosystem, if your impression is different
or if you have some feedback, don&amp;rsquo;t hesitate to file an issue on the
&lt;a href=&#34;https://github.com/JuliaGraphs&#34; target=&#34;_blank&#34;&gt;corresponding package&lt;/a&gt;, some awesome people
will help you figure things out as they helped me.&lt;/p&gt;

&lt;p&gt;There is one thing we ignored in our model, it&amp;rsquo;s the number of transactions
realized. Using this as an objective turns the problem into a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Integer_programming#Variants&#34; target=&#34;_blank&#34;&gt;Mixed-Integer Linear Programming&lt;/a&gt; one,
which are much harder to solve and cannot use simple flow techniques. However,
I still haven&amp;rsquo;t found a case where our simple approach does not yield the
smallest number of transactions.&lt;/p&gt;

&lt;p&gt;Final word: I started the idea of this article long before the crypto-madness
(September actually), when currencies where still considered as boring,
nerdy or both, sorry about following the (late) hype. I even changed
GraphCoin symbol to GPHC because I found another one with which my initial
name conflicted.&lt;/p&gt;

&lt;p&gt;If you have questions or remarks on LightGraphs, LightGraphsFlows, the article
or anything related, don&amp;rsquo;t hesitate to &lt;a href=&#34;http://twitter.com/MathieuBesancon/&#34; target=&#34;_blank&#34;&gt;ping me&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Edits:&lt;br /&gt;
Special thanks to &lt;a href=&#34;http://www.bromberger.com/&#34; target=&#34;_blank&#34;&gt;Seth Bromberger&lt;/a&gt; for the review.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The cover image was created using
&lt;a href=&#34;https://github.com/JuliaGraphs/GraphPlot.jl&#34; target=&#34;_blank&#34;&gt;GraphPlot.jl&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[1] James Fairbanks Seth Bromberger and other contributors. Juliagraphs/LightGraphs.jl:
Lightgraphs, 2017, &lt;a href=&#34;https://doi.org/10.5281/zenodo.889971&#34; target=&#34;_blank&#34;&gt;https://doi.org/10.5281/zenodo.889971&lt;/a&gt;. DOI: 10.5281/zenodo.889971&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DifferentialEquations.jl - part 2: decision from the model</title>
      <link>https://mbesancon.github.io/post/2017-12-20-diffeq-julia2/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2017-12-20-diffeq-julia2/</guid>
      <description>

&lt;p&gt;In the &lt;a href=&#34;https://mbesancon.github.io/post/2017-12-14-diffeq-julia&#34;&gt;last article&lt;/a&gt;, we explored different modeling options for a
three-component systems which could represent the dynamics of a chemical
reaction or a disease propagation in a population. Building on top of this
model, we will formulate a desirable outcome and find a decision which
maximizes this outcome.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In addition to the packages imported in the last post,
we will also use &lt;a href=&#34;https://github.com/robertfeldt/BlackBoxOptim.jl&#34; target=&#34;_blank&#34;&gt;BlackBoxOptim.jl&lt;/a&gt;:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; DifferentialEquations
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; DiffEq &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DifferentialEquations
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; Plots
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; Optim
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&#34;the-model&#34;&gt;The model&lt;/h2&gt;

&lt;p&gt;The same chemical system with three components, A, B and R will be used:
$$A + B → 2B$$  $$B → R$$&lt;/p&gt;

&lt;p&gt;The reactor where the reaction occurs must remain active for one minute.
Let&amp;rsquo;s imagine that $B$ is our valuable component while $R$ is a waste.
We want to maximize the quantity of $B$ present within the system after one
minute, that&amp;rsquo;s the objective function. For that purpose, we can choose to add
a certain quantity of new $A$ within the reactor at any point.
$$t_{inject} ∈ [0,t_{final}]$$.&lt;/p&gt;

&lt;h2 id=&#34;implementing-the-injection&#34;&gt;Implementing the injection&lt;/h2&gt;

&lt;p&gt;There is one major feature of DifferentialEquations.jl we haven&amp;rsquo;t explored yet:
the &lt;a href=&#34;http://docs.juliadiffeq.org/latest/features/callback_functions.html&#34; target=&#34;_blank&#34;&gt;event handling system&lt;/a&gt;.
This allows for the system state to change at a particular point in time,
depending on conditions on the time, state, etc&amp;hellip;&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# defining the problem&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.8&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;3.0&lt;/span&gt;
diffeq &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(du, u, p, t)
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
u0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color: #FF6600&#34;&gt;49.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;]
tspan &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;)
prob &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ODEProblem(diffeq, u0, tspan)

&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; A_inj &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;30&lt;/span&gt;
inject_new &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(t0)
    condition(u, t, integrator) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; t0 &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; t
    affect! &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(integrator)
        integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; A_inj
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    callback &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ContinuousCallback(condition, affect!)
    sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(prob, callback&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;callback)
    sol
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# trying it out with an injection at t=0.4&lt;/span&gt;
sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; inject_new(&lt;span style=&#34;color: #FF6600&#34;&gt;0.4&lt;/span&gt;)
Plots&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(sol)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/inject.png&#34; alt=&#34;Injection simulation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;ContinuousCallback&lt;/code&gt; construct is the central element here, it takes as
information:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When to trigger the event, implemented as the &lt;code&gt;condition&lt;/code&gt; function. It triggers
when this function reaches 0, which is here the case when $t = t_0$.&lt;/li&gt;
&lt;li&gt;What to do with the state at that moment. The state is encapsulated within
the &lt;em&gt;integrator&lt;/em&gt; variable. In our case, we add 30 units to the concentration in &lt;em&gt;A&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As we can see on the plot, a discontinuity appears on the concentration in A
at the injection time, the concentration in B restarts increasing.&lt;/p&gt;

&lt;h2 id=&#34;finding-the-optimal-injection-time-visual-approach&#34;&gt;Finding the optimal injection time: visual approach&lt;/h2&gt;

&lt;p&gt;From the previously built function, we can get the whole solution with a given
injection time, and from that the final state of the system.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;tinj_span &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.05&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0.005&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0.95&lt;/span&gt;
final_b &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [inject_new(tinj)&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;][&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; tinj &lt;span style=&#34;color: #006699&#34;&gt;in&lt;/span&gt; tinj_span]
Plots&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(tinj_span, final_b)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using a plain for comprehension, we fetch the solution of the simulation for
the callback built with each $t_{inject}$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/optimal_inject.png&#34; alt=&#34;Quantity of B&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Injecting $A$ too soon lets too much time for the created $B$ to turn into $R$,
but injecting it too late does not let enough time for $B$ to be produced from
the injected $A$. The optimum seems to be around ≈ 0.82,&lt;/p&gt;

&lt;h2 id=&#34;finding-the-optimum-using-optim-jl&#34;&gt;Finding the optimum using Optim.jl&lt;/h2&gt;

&lt;p&gt;The package requires an objective function which takes a vector as input.
In our case, the decision is modeled as a single variable (the injection time),
&lt;strong&gt;it&amp;rsquo;s crucial to make the objective use a vector nonetheless&lt;/strong&gt;, otherwise
calling the solver will just explode with cryptic errors.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;compute_finalb &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; tinj &lt;span style=&#34;color: #555555&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; inject_new(tinj[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;])&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;][&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
Optim&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;optimize(compute_finalb, &lt;span style=&#34;color: #FF6600&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;0.9&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We get a detailed result of the optimization including the method and iterations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Algorithm: Brent&#39;s Method
* Search Interval: [0.100000, 0.900000]
* Minimizer: 8.355578e-01
* Minimum: -2.403937e+01
* Iterations: 13
* Convergence: max(|x - x_upper|, |x - x_lower|) &amp;lt;= 2*(1.5e-08*|x|+2.2e-16): true
* Objective Function Calls: 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function &lt;code&gt;inject_new&lt;/code&gt; we defined above returns the complete solution
of the simulation, we get the state matrix &lt;code&gt;u&lt;/code&gt;, from which we extract the
final state &lt;code&gt;u[end]&lt;/code&gt;, and then the second component, the concentration in
B: &lt;code&gt;u[end][2]&lt;/code&gt;. The optimization algorithm minimizes the objective, while we want
to maximize the final concentration of B, hence the -1 multiplier used for&lt;br /&gt;
&lt;code&gt;compute_finalb&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We can use the Optim.jl package because our function is twice differentiable,
the best improvement direction is easy to compute.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;extending-the-model&#34;&gt;Extending the model&lt;/h2&gt;

&lt;p&gt;The decision over one variable was pretty straightforward. We are going to
extend it by changing how the $A$ component is added at $t_{inject}$.
Instead of being completely dissolved, a part of the component will keep being
poured in after $t_{inject}$. So the decision will be composed of two variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The time of the beginning of the injection&lt;/li&gt;
&lt;li&gt;The part of $A$ to inject directly and the part to inject in a
continuous fashion. We will note the fraction injected directly $\delta$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given a fixed available quantity $A₀$ and a fraction to inject directly $\delta$,
the concentration in A is increased of $\delta \cdot A₀$ at time $t_{inject}$,
after which the rate of change of the concentration in A is increased by a
constant amount, until the total amount of A injected (directly and over time)
is equal to the planned quantity.&lt;/p&gt;

&lt;p&gt;We need a new variable in the state of the system, $u_4(t)$, which stands
for the input flow of A being active or not.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$u(t) = 0$ if $t &amp;lt; t_{inject}$&lt;/li&gt;
&lt;li&gt;$u(t) = 0$ if the total flow of A which has been injected is equal to the planned quantity&lt;/li&gt;
&lt;li&gt;$u(t) = \dot{A}\ $ otherwise, with $\dot{A}\ $ the rate at which A is being poured.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;new-julia-equations&#34;&gt;New Julia equations&lt;/h2&gt;

&lt;p&gt;We already built the key components in the previous sections. This time we need
two events:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A is directly injected at $t_{inject}$, and then starts being poured at constant rate&lt;/li&gt;
&lt;li&gt;A stops being poured when the total quantity has been used&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; inj_quantity &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;30.0&lt;/span&gt;;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; inj_rate &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;40.0&lt;/span&gt;;

diffeq_extended &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(du, u, p, t)
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;

u0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color: #FF6600&#34;&gt;49.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;]
tspan &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;)
prob &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ODEProblem(diffeq_extended, u0, tspan)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We wrap the solution building process into a function taking the starting time
and the fraction being directly injected as parameters:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;inject_progressive &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(t0, direct_frac)
    condition_start(u, t, integrator) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; t0 &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; t
    affect_start! &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(integrator)
        integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; inj_quantity &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; direct_frac
        integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; inj_rate
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    callback_start &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ContinuousCallback(
        condition_start, affect_start!, save_positions&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;true&lt;/span&gt;, &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;true&lt;/span&gt;)
    )
    condition_end(u, t, integrator) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; (t &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; t0) &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; inj_rate &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; inj_quantity &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; direct_frac)
    affect_end! &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(integrator)
        integrator&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
    callback_end &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ContinuousCallback(condition_end, affect_end!, save_positions&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;true&lt;/span&gt;, &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;true&lt;/span&gt;))
    sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(prob, callback&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;CallbackSet(callback_start, callback_end), dtmax&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0.005&lt;/span&gt;)
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;

Plots&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(inject_progressive(&lt;span style=&#34;color: #FF6600&#34;&gt;0.6&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0.6&lt;/span&gt;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can notice &lt;code&gt;callback_start&lt;/code&gt; being identical to the model we previously built,
while &lt;code&gt;condition_end&lt;/code&gt; corresponds to the time when the total injected
quantity reaches &lt;code&gt;inj_quantity&lt;/code&gt;. The first events activates $u_4$ and sets it
to the nominal flow, while the second callback resets it to 0.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/const_rate.png&#34; alt=&#34;Constant rate&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Optim.jl can be re-used to determine the optimal decision:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; BlackBoxOptim
objective &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(x)
    sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; inject_progressive(x[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;], x[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])
    &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;sol&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;u[&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;][&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
BlackBoxOptim&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;bboptimize(objective, SearchRange&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;[(&lt;span style=&#34;color: #FF6600&#34;&gt;0.1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0.9&lt;/span&gt;),(&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;)], NumDimensions&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The optimal solution corresponds to a complete direct injection
($\delta \approx 1$) with $t_{inject}^{opt}$ identical to the previous model.
This means pouring the A component in a continuous fashion does not allow to
produce more $B$ at the end of the minute.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We could still built on top of this model to keep refining it, taking more
phenomena into account (what if the reactions produce heat and are sensitive
to temperature?). The structures describing models built with
DifferentialEquations.jl are transparent and easy to use for further manipulations.&lt;/p&gt;

&lt;p&gt;One point on which I place expectations is some additional interoperability
between DifferentialEquations.jl and &lt;a href=&#34;https://github.com/JuliaOpt/JuMP.jl&#34; target=&#34;_blank&#34;&gt;JuMP&lt;/a&gt;,
a Julia meta-package for optimization. Some great work was already performed to
combine the two systems, one use case that has been described is the parameter
identification problem (given the evolution of concentration in the system,
identify the α and β parameters).&lt;/p&gt;

&lt;p&gt;But given that the function I built from a parameter was a black box
(without an explicit formula, not a gradient), I had to use BlackBoxOptim,
which is amazingly straightforward, but feels a bit overkill for smooth
functions as presented here. Maybe there is a different way to build the
objective function, using parametrized functions for instance, which could
make it transparent to optimization solvers.&lt;/p&gt;

&lt;p&gt;If somebody has info on that last point or feedback, additional info you&amp;rsquo;d like
to share regarding this post, hit me on &lt;a href=&#34;https://twitter.com/MathieuBesancon&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;.
Thanks for reading!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;edits-and-improvements&#34;&gt;Edits and improvements&lt;/h2&gt;

&lt;p&gt;2018-01-31:&lt;br /&gt;
I updated this post to adapt to the new DifferentialEquations.jl
interface. I also used Optim.jl for the first case without calling BlackBoxOptim.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;2017-12-20:&lt;br /&gt;
Of course, BlackBoxOptim.jl was not the most appropriate algorithm as
predicted. &lt;a href=&#34;https://twitter.com/pkofod&#34; target=&#34;_blank&#34;&gt;Patrick&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/ChrisRackauckas&#34; target=&#34;_blank&#34;&gt;Chris&lt;/a&gt;
gave me some hints in &lt;a href=&#34;https://twitter.com/MathieuBesancon/status/943662063074906112&#34; target=&#34;_blank&#34;&gt;this thread&lt;/a&gt;
and I gave &lt;a href=&#34;https://github.com/JuliaNLSolvers/Optim.jl&#34; target=&#34;_blank&#34;&gt;Optim.jl&lt;/a&gt; a try.&lt;/p&gt;

&lt;p&gt;This package has a range of algorithms to choose from depending on the
structure of the function and the knowledge of its gradient and Hessian.
The goal is continuous optimization, (as opposed to BlackBoxOptim.jl which supports
more exotic search spaces).&lt;/p&gt;

&lt;p&gt;Finding the optimum $t_{inject}$ of the first problem is pretty simple:
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; Optim
Optim&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;optimize(compute_finalb, &lt;span style=&#34;color: #FF6600&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;0.9&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;This yields the following information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Results of Optimization Algorithm
 * Algorithm: Brent&#39;s Method
 * Search Interval: [0.100000, 0.900000]
 * Minimizer: 8.355891e-01
 * Minimum: -2.403824e+01
 * Iterations: 13
 * Convergence: max(|x - x_upper|, |x - x_lower|) &amp;lt;= 2*(1.5e-08*|x|+2.2e-16): true
 * Objective Function Calls: 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;14 calls to the objective function, pretty neat compared to the hundreds of
BlackBoxOptim. We also confirm the optimum of &lt;code&gt;0.8355891&lt;/code&gt;. Not yet sure we could
use Optim.jl for the second case (boxed multivariate optimization without explicit gradient).&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font size=&#34;0.7&#34;&gt;
 [1] Cover image: Lorenz attractor on &lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Lorenz_attractor2.svg&#34; target=&#34;_blank&#34;&gt;Wikimedia&lt;/a&gt;, again.
&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with DifferentialEquations.jl</title>
      <link>https://mbesancon.github.io/post/2017-12-14-diffeq-julia/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2017-12-14-diffeq-julia/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/JuliaDiffEq/DifferentialEquations.jl&#34; target=&#34;_blank&#34;&gt;DifferentialEquations.jl&lt;/a&gt;
came to be a key component of Julia&amp;rsquo;s scientific ecosystem. After checking the
JuliaCon talk of its creator, I couldn&amp;rsquo;t wait to start building stuff with it,
so I created and developed a simple example detailed in this blog post.
Starting from a basic ordinary differential equation (ODE), we add noise,
making it stochastic, and finally turn it into a discrete version.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Before running the code below, two imports will be used:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; DifferentialEquations
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;const&lt;/span&gt; DiffEq &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DifferentialEquations
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; Plots
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I tend to prefer explicit imports in Julia code, it helps to see from which
part each function and type comes. As &lt;code&gt;DifferentialEquations&lt;/code&gt; is longuish to
write, we use an alias in the rest of the code.&lt;/p&gt;

&lt;h2 id=&#34;the-model&#34;&gt;The model&lt;/h2&gt;

&lt;p&gt;We use a simple 3-element state in a differential equation. Depending on your
background, pick the interpretation you prefer:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;An SIR model, standing for susceptible, infected, and recovered, directly
inspired by the talk and by the &lt;a href=&#34;https://github.com/sdwfrost/Gillespie.jl&#34; target=&#34;_blank&#34;&gt;Gillespie.jl&lt;/a&gt;
package. We have a total population with healthy people, infected people
(after they catch the disease) and recovered (after they heal from the disease).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A chemical system with three components, A, B and R.
$$A + B → 2B$$  $$B → R$$&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After searching my memory for chemical engineering courses and the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Autocatalysis&#34; target=&#34;_blank&#34;&gt;universal source of knowledge&lt;/a&gt;,
I could confirm the first reaction is an autocatalysis, while the second is
a simple reaction. An autocatalysis means that B molecules turn A molecules
into B, without being consumed.&lt;/p&gt;

&lt;p&gt;The first example is easier to represent as a discrete problem: finite
populations make more sense when talking about people. However, it can be seen
as getting closer to a continuous differential equation as the number of people
get higher. The second model makes more sense in a continuous version as we are
dealing with concentrations of chemical components.&lt;/p&gt;

&lt;h2 id=&#34;a-first-continuous-model&#34;&gt;A first continuous model&lt;/h2&gt;

&lt;p&gt;Following the tutorials from the
&lt;a href=&#34;http://docs.juliadiffeq.org/latest/tutorials/ode_example.html#Example-2:-Solving-Systems-of-Equations-1&#34; target=&#34;_blank&#34;&gt;official package website&lt;/a&gt;,
we can build our system from:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A system of differential equations: how does the system behave (dynamically)&lt;/li&gt;
&lt;li&gt;Initial conditions: where does the system start&lt;/li&gt;
&lt;li&gt;A time span: how long do we want to observe the system&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The system state can be written as:
$$u(t) =
\begin{bmatrix}
u₁(t) \&lt;br /&gt;
u₂(t) \&lt;br /&gt;
u₃(t)&lt;br /&gt;
\end{bmatrix}^T
$$&lt;/p&gt;

&lt;p&gt;With the behavior described as:
$$
\dot{u}(t) = f(u,t)
$$
And the initial conditions $u(0) = u₀$.&lt;/p&gt;

&lt;p&gt;In Julia with DifferentialEquations, this becomes:
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;α &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.8&lt;/span&gt;
β &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;3.0&lt;/span&gt;
diffeq &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(du, u, p, t)
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; α &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; β &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
u₀ &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color: #FF6600&#34;&gt;49.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;;&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;]
tspan &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;1.0&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;&lt;code&gt;diffeq&lt;/code&gt; models the dynamic behavior, &lt;code&gt;u₀&lt;/code&gt; the starting conditions
and &lt;code&gt;tspan&lt;/code&gt; the time range over which we observe the system
evolution. Note that the &lt;code&gt;diffeq&lt;/code&gt; function also take a &lt;code&gt;p&lt;/code&gt; argument for parameters,
in which we could have stored $\alpha$ and $\beta$.&lt;/p&gt;

&lt;p&gt;We know that our equation is smooth, so we&amp;rsquo;ll let
&lt;code&gt;DifferentialEquations.jl&lt;/code&gt; figure out the solver. The general API
of the package is built around two steps:&lt;br /&gt;
1. Building a problem/model from behavior and initial conditions
2. Solving the problem using a solver of our choice and providing additional
information on how to solve it, yielding a solution.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;prob &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ODEProblem(diffeq, u₀, tspan)
sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(prob)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One very nice property of solutions produced by the package is that they
contain a direct way to produce plots. This is fairly common in Julia to
implement methods from other packages, here the &lt;code&gt;ODESolution&lt;/code&gt; type implements
Plots.plot:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;Plots&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(sol)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/smooth.png&#34; alt=&#34;Solution to the ODE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If we use the disease propagation example, $u₁(t)$ is the number of
healthy people who haven&amp;rsquo;t been infected. It starts high, which makes the rate
of infection by the diseased population moderate. As the number of sick people
increases, the rate of infection increases: there are more and more possible
contacts between healthy and sick people.&lt;/p&gt;

&lt;p&gt;As the number of sick people increases, the recovery rate also increases,
absorbing more sick people. So the &amp;ldquo;physics&amp;rdquo; behind the problem makes sense
with what we observe on the curve.&lt;/p&gt;

&lt;p&gt;A key property to notice is the mass conservation: the sum of the three elements
of the vector is constant (the total population in the health case). This makes
sense from the point of view of the equations:
$$\frac{du₁}{dt} + \frac{du₂}{dt} + \frac{du_3}{dt} = 0$$&lt;/p&gt;

&lt;h2 id=&#34;adding-randomness-first-attempt-with-a-simple-sde&#34;&gt;Adding randomness: first attempt with a simple SDE&lt;/h2&gt;

&lt;p&gt;The previous model works successfully, but remains naive. On small populations,
the rate of contamination and recovery cannot be so smooth. What if some sick
people isolate themselves from others for an hour or so, what there is a
meeting organized, with higher chances of contacts? All these plausible events
create different scenarios that are more or less likely to happen.&lt;/p&gt;

&lt;p&gt;To represent this, the rate of change of the three variables of the system
can be considered as composed of a deterministic part and of a random variation.
One standard representation for this, as laid out in the
&lt;a href=&#34;http://docs.juliadiffeq.org/latest/tutorials/sde_example.html&#34; target=&#34;_blank&#34;&gt;package documentation&lt;/a&gt;
is the following:
$$
du = f(u,t) dt + ∑ gᵢ(u,t) dWᵢ
$$&lt;/p&gt;

&lt;p&gt;In our case, we could consider two points of randomness at the two interactions
(one for the transition from healthy to sick, and one from sick to recovered).&lt;/p&gt;

&lt;h1 id=&#34;stochastic-version&#34;&gt;Stochastic version&lt;/h1&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;σ1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.07&lt;/span&gt;
σ2 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.4&lt;/span&gt;
noise_func &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(du, u, p, t)
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; σ1 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; σ2 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]  &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;

stoch_prob &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;SDEProblem(diffeq, noise_func, u₀, tspan)
sol_stoch &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(stoch_prob, DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;SRIW1())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that we also change the solver provided to the &lt;code&gt;solve&lt;/code&gt; function to adapt
to stochastic equations. The last variation is set to the opposite of the sum
of the two others to compensate the two other variations (we said we had only
one randomness phenomenon per state transition).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/sde.png&#34; alt=&#34;SDE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Woops, something went wrong. This time the mass conservation doesn&amp;rsquo;t hold,
we finish with a population below the initial condition. What is wrong is that
we don&amp;rsquo;t define the &lt;strong&gt;variation&lt;/strong&gt; but the &lt;em&gt;gᵢ(u,t)&lt;/em&gt; function, which is then
multiplied by &lt;em&gt;dWᵢ&lt;/em&gt;. Since we used the function signature corresponding to
the diagonal noise, there is a random component per $uᵢ$ variable.&lt;/p&gt;

&lt;h2 id=&#34;adding-randomness-second-attempt-with-non-diagonal-noise&#34;&gt;Adding randomness: second attempt with non-diagonal noise&lt;/h2&gt;

&lt;p&gt;As explained above, we need one source of randomness for each transition.
This results in a $G(u,t)$ matrix of $3 × 2$. We can then make sure that the
the sum of variations for the three variables cancel out to keep a constant
total population.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;noise_func_cons &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;function&lt;/span&gt;(du, u, p, t)
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; σ1 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; σ1 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; σ2 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.0&lt;/span&gt;
    du[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; σ2 &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; u[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;end&lt;/span&gt;
sde_cons &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;SDEProblem(
    diffeq, noise_func_cons, u₀, tspan,
    noise_rate_prototype&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;zeros(&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
)
cons_solution &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(sde_cons, DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;EM(), dt&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;500&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also provide a &lt;code&gt;noise_rate_prototype&lt;/code&gt; parameter to the problem builder to
indicate we don&amp;rsquo;t want to use a diagonal noise.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/sde_nondiag.png&#34; alt=&#34;SDE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This time the population conservation holds, at any point in time the sum of
the $uᵢ(t)$ remains 50.&lt;/p&gt;

&lt;h2 id=&#34;discretizing-gillespie-model&#34;&gt;Discretizing: Gillespie model&lt;/h2&gt;

&lt;p&gt;The models we produced so far represent well the chemical reaction problem,
but a bit less the disease propagation. We are using continuous quantities
to represent discrete populations, how do we interpret 0.6 people sick at a time?&lt;/p&gt;

&lt;p&gt;One major strength of the package is its effortless integration of discrete
phenomena in a model, alone or combined with continuous dynamics. Our model
follows exactly the package tutorial on
&lt;a href=&#34;http://docs.juliadiffeq.org/latest/tutorials/discrete_stochastic_example.html&#34; target=&#34;_blank&#34;&gt;discrete stochastic problems&lt;/a&gt;,
so building it should be straightforward.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;infect_rate &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;Reaction(α, [&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;],[(&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;),(&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;)])
recover_rate &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;Reaction(β, [&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;],[(&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;),(&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;)])
disc_prob &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;GillespieProblem(
    DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;DiscreteProblem(round&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;(&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;,u₀), tspan),
    DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;Direct(),
    infect_rate, recover_rate,
)
disc_sol &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;solve(disc_prob, DiffEq&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;Discrete());
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We define the infection and recovery rate and the variables $uᵢ$ that are
affected, and call the Discrete solver. The Plots.jl integration once again
yields a direct representation of the solution over the time span.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/DiffEq/discrete.png&#34; alt=&#34;SDE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Again, the conservation of the total population is guaranteed by the effect of
the jumps deleting one unit from a population to add it to the other.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The DifferentialEquations.jl package went from a good surprise to a key tool in
my scientific computing toolbox. It does not require learning another embedded
language but makes use of real idiomatic Julia. The interface is clean and
working on edge cases does not feel hacky. I&amp;rsquo;ll be looking forward to using
it in my PhD or side-hacks, especially combined to the
&lt;a href=&#34;https://github.com/JuliaOpt/JuMP.jl&#34; target=&#34;_blank&#34;&gt;JuMP.jl&lt;/a&gt; package: DifferentialEquations
used to build simulations and JuMP to optimize a cost function on top of the
created model.&lt;/p&gt;

&lt;p&gt;Thanks for reading, hit me on &lt;a href=&#34;https://twitter.com/MathieuBesancon&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;
for feedback or questions ;)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Edits:&lt;/p&gt;

&lt;p&gt;I updated this post to fit the new DifferentialEquations.jl 4.0 syntax. Some
changes are breaking the previous API, it can be worth it to check it out
&lt;a href=&#34;http://juliadiffeq.org/2018/01/24/Parameters.html&#34; target=&#34;_blank&#34;&gt;in detail&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://twitter.com/ChrisRackauckas&#34; target=&#34;_blank&#34;&gt;Chris&lt;/a&gt;, the creator and main developer
of DifferentialEquations.jl, gave me valuable tips on two
points which have been edited in the article. You can find the thread
&lt;a href=&#34;https://twitter.com/MathieuBesancon/status/941825252744507392&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Import aliases should use &lt;code&gt;const PackageAlias = PackageName&lt;/code&gt; for type
stability. This allows the compiler to generate efficient code.
Some further mentions of type-stability can be found in the
&lt;a href=&#34;https://docs.julialang.org/en/latest/manual/performance-tips&#34; target=&#34;_blank&#34;&gt;official doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The second attempts uses non-diagonal noise, the &amp;ldquo;:additive&amp;rdquo; hint I passed
to the solve function does not hold. Furthermore, the appropriate algorithm in
that case is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method&#34; target=&#34;_blank&#34;&gt;Euler-Maruyama method&lt;/a&gt;
.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many thanks to him for these tips, having such devoted and friendly developers
is also what makes an open-source project successful.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font size=&#34;0.7&#34;&gt;
 [1] Cover image: Lorenz attractor on &lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Lorenz_attractor2.svg&#34; target=&#34;_blank&#34;&gt;Wikimedia&lt;/a&gt;
&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Switching my work flow to Pomodoro for grad studies - part I: motivation  </title>
      <link>https://mbesancon.github.io/post/2017-10-19-tomate-cli/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2017-10-19-tomate-cli/</guid>
      <description>

&lt;p&gt;The start of my journey as a PhD student last September was a big step, but
also an opportunity to review and improve my working habits. My day time
had to be used properly, both for results&amp;rsquo; sake and to be able to keep
a balanced life.&lt;/p&gt;

&lt;p&gt;I had been introduced to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pomodoro_Technique&#34; target=&#34;_blank&#34;&gt;Pomodoro technique&lt;/a&gt;
at Equisense (thanks &lt;a href=&#34;https://twitter.com/CamilleSaute&#34; target=&#34;_blank&#34;&gt;Camille&lt;/a&gt;!) but
remained skeptical as for its potential value within my work
flow at the time.&lt;/p&gt;

&lt;p&gt;To make it short, the technique consists in the following steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Decide what task should be worked on.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Allocate a given time to work (around 25 minutes)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Set a timer and get to work&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;When the time is up, make a short pause (~5 minutes), then repeat&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;After 4 work sprints, take a longer break (~15-30 minutes)&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;what-was-wrong-with-that&#34;&gt;What was wrong with that?&lt;/h2&gt;

&lt;p&gt;The development, test and operation phases were generally self-determining
and lead to sprints from 20 to 120 minutes (that length isn&amp;rsquo;t surprising
for some tasks and when highly focused). These were also often
interrupted by team interactions (required concertation with members
of the tech and product team, backend-specific collaborative
problem-solving, &amp;hellip;). The main point was that
&lt;strong&gt;there are enough spontaneous interruptions of the work flow, no need to introduce an additional artificial one&lt;/strong&gt;.
As I look back, I still think this was a valid reason
not to use this technique.&lt;/p&gt;

&lt;h2 id=&#34;what-has-changed&#34;&gt;What has changed?&lt;/h2&gt;

&lt;p&gt;Time management as a grad student has to be un- and re-learned:
rules are different, criteria for success change and so on.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/tomate/phd_time.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Time management seen by PhD comics [2]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;problem-structure-programming-at-a-startup-vs-applied-math&#34;&gt;Problem structure: programming at a startup vs. applied math&lt;/h3&gt;

&lt;p&gt;In my case, the major part of the workload switched from an
implementation-heavy to a modeling-heavy context. As such,
the work phases tend to be longer and with an heavier
cognitive load. I am not saying that programming is
easier, but I&amp;rsquo;m pretty sure mathematics almost always
requires to keep more information in mind while working
on a problem. Another opinion is that the part of
instinct to find a path towards a solution is higher
in mathematics.&lt;/p&gt;

&lt;p&gt;While programming, there are some key techniques that
reduce the number of possible sources to a problem:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Getting information on the state of the program at a given point (logging, debugging, printing to &lt;code&gt;stdout&lt;/code&gt;)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Testing the behavior of an isolated piece of the program with given input&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These techniques also work for scientific computing of course, but are
harder to apply to both modeling and symbolic calculus, the different
pieces of the problem have to be combined to find special structures
which allow for a resolution. More solutions also tend to come
while NOT looking at mathematical problem than for programming
problems, where solutions come either in front of the code or when
voluntarily thinking of the problem.&lt;/p&gt;

&lt;h3 id=&#34;team-dependent-work-vs-figure-it-out-for-yourself&#34;&gt;Team-dependent work vs. figure it out for yourself&lt;/h3&gt;

&lt;p&gt;Most startups obviously value team work, it is one of the
group skills that differentiate companies building great
things from the ones stuck in an eternal early stage.
This was even more true at Equisense where collaboration
and product development were both very synchronous by
modern standards. It had cons but ease two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Speed of product development&lt;/strong&gt;. Lots of team under-estimate post-development coordination, the last meters of the sprint to have a feature ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Programming by constraints&lt;/strong&gt;. Because of fast interactions between the people responsible for the different components, constraints from each one is quickly communicated and the modeling process is defined accounting for them right away.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now in research, especially in applied mathematics, the work is
mostly independent, synchronization happens when working
on a joined project for instance. This means that all the
interruptions that were happening throughout the day are
now gone!
&lt;strong&gt;Nothing would stop you from working day and night without a break&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Two key results of this change of work style are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Work sprints are not naturally bound anymore, obviously with decreasing efficiency&lt;/li&gt;
&lt;li&gt;Few to no interactions interrupt the sprints either&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My conclusion was the necessity of a time management technique
and associated tools, with a low cognitive overhead and bringing
as little distraction as possible.&lt;/p&gt;

&lt;p&gt;From these criteria, I rejected a mobile app,
smartphones are great to bring different sources
of information and communication channels together,
not for remaining focused for hours,
&lt;strong&gt;mobile apps are designed to catch and retain attention&lt;/strong&gt;,
that&amp;rsquo;s simply part of their business model. I also rejected
web-based solutions for the constraint of firing up
a browser, amongst the heaviest pieces of software on our
modern desktops, just to start a working session.&lt;/p&gt;

&lt;p&gt;So desktop GUI or CLI it is. Even though there is the
&lt;a href=&#34;http://gnomepomodoro.org/&#34; target=&#34;_blank&#34;&gt;gnomepomodoro project&lt;/a&gt;, it did not seem compatible with all
Linux desktops. At that point, I realized the amount of
work to build a Pomodoro was low, the requirements and
constraints well known, I throw ideas
together and start coding.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll explain the initial development and iterations of
the app in Go in a second article, if you liked this one,
let me know!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Sources and images:&lt;br /&gt;
&lt;a href=&#34;https://pixabay.com/en/tomatoes-vegetables-red-delicious-73913&#34; target=&#34;_blank&#34;&gt;1&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://substance-en.etsmtl.ca/wp-content/uploads/2014/09/2.gif&#34; target=&#34;_blank&#34;&gt;2&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving my content creation to a home-made Hugo site</title>
      <link>https://mbesancon.github.io/post/2017-09-05-moving-content-hugo/</link>
      <pubDate>Tue, 05 Sep 2017 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2017-09-05-moving-content-hugo/</guid>
      <description>

&lt;p&gt;Last weeks have been pretty intense. I officially left Equisense and  started
a joined PhD project between INRIA Lille and Ecole Polytechnique Montreal.
I had been preparing for this fresh start for several months and also wanted
to evolve in my content creation process.&lt;/p&gt;

&lt;h2 id=&#34;a-journey-from-plain-markdown-to-hugo&#34;&gt;A journey from plain markdown to Hugo&lt;/h2&gt;

&lt;p&gt;I started writing articles to keep track of my learning paths on various topics,
including numerical techniques, data analysis and programming. My first articles
were either plain or Rmarkdown-generated Markdowns on a Github repository.&lt;/p&gt;

&lt;p&gt;As I was slowly moving from R to Python, Jupyter notebook became pretty handy
to mix paragraphs, code snippets, results and charts. It also forced me to
quit declaring and modifying variables, an annoying habit got from always
having a REPL and text editor bundled in most scientific computing IDEs
(Matlab, Scilab, RStudio, Jupyter).&lt;/p&gt;

&lt;p&gt;Great, the articles were not centralized though but split into their Github
repositories, you have to admit this is not the most user-friendly browsing
experience. I found several blogs running on &lt;a href=&#34;https://jekyllrb.com&#34; target=&#34;_blank&#34;&gt;Jekyll&lt;/a&gt;
and I decided to give it a try. For someone who is not fond of struggles with
front-end side layout issues, this was a true gift, I could easily reuse
templates from front-end developers and designers (special thanks for the
awesome &lt;a href=&#34;http://hemangsk.github.io/Gravity&#34; target=&#34;_blank&#34;&gt;Gravity project&lt;/a&gt;)
without much struggle and focus on what I liked: building projects and
writing content.&lt;/p&gt;

&lt;h2 id=&#34;switching-to-the-writing-platform&#34;&gt;Switching to THE writing platform&lt;/h2&gt;

&lt;p&gt;I kept maintaining the Jekyll blog until almost exactly one year ago. During
that time, I was mostly writing in the context of a side-project or thinking on
our journey at &lt;a href=&#34;https://www.equisense.com&#34; target=&#34;_blank&#34;&gt;Equisense&lt;/a&gt;. This raised new
requirements for the writing process such as collaborative writing, review from
friends, seeing the overall picture we were sending as a team from the sum of
our articles.&lt;/p&gt;

&lt;p&gt;For these reasons, my articles gradually switched to Medium,
first published as an individual, then on the
&lt;a href=&#34;https://medium.com/equisense&#34; target=&#34;_blank&#34;&gt;Equisense page&lt;/a&gt;. This was a very productive time
for writing as we encouraged one another and had a direct impact on the way we
presented the team, how we work and our learning path: an invaluable tool to
help candidates decide whether the company was a fit for them and to ease the
onboading.&lt;/p&gt;

&lt;h2 id=&#34;if-medium-works-why-would-anyone-go-back-to-writing-everything-from-scratch&#34;&gt;If Medium works, why would anyone go back to writing everything from scratch?&lt;/h2&gt;

&lt;p&gt;I really enjoy the writing experience on Medium, with some drawbacks.
Medium&amp;rsquo;s design is very opinionated, that&amp;rsquo;s a part of what makes it a experience.
However, leaving some choices on key topics is essential (at least to me) on the
content-creation side.
I believe this should be the case on any two-sided plateform:
&lt;strong&gt;be opinionated on the user-side, leave flexibility on the creator side.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The perfect example is the bright screen. It ensures the Medium experience is
consistent with the unique font, background etc&amp;hellip; But writing on a dark screen
is a lot more comfortable, especially when you&amp;rsquo;re used to it or when your eyes
are more light-sensitive: writing late in the evening or early in the morning
was not conceivable to me on the Medium interface. The hack I used was to write
everything on &lt;a href=&#34;https://atom.io&#34; target=&#34;_blank&#34;&gt;Atom&lt;/a&gt;, then paste everything to Medium once the
first draft was ready, still a bit of a pain.&lt;/p&gt;

&lt;p&gt;This might seem minor as a reason to switch, but the root behind it is more
essential: &lt;strong&gt;Medium is a platform, you&amp;rsquo;re therefore a user, not an owner&lt;/strong&gt;.
Despite its global success, the company is still young and looking for the
right model. Nothing tells me the model they choose tomorrow will be one I
want to contribute to (how paid content will be managed for instance).
Switching platforms for written content is a lot more tedious than choosing well
at the beginning. This new step in my professional and personal life is the
perfect occasion to rethink that commitment, I will still be re-publishing
content to Medium, but not as the primary source.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Company values: stop trying to dictate who you are</title>
      <link>https://mbesancon.github.io/post/2016-10-7-company-values/</link>
      <pubDate>Fri, 07 Oct 2016 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-10-7-company-values/</guid>
      <description>

&lt;p&gt;Two weeks ago, the Equisense &lt;a href=&#34;http://equisense.com/en/about.html&#34; target=&#34;_blank&#34;&gt;team&lt;/a&gt; spent a
couple days together near the ocean in northern France. The goal was to get to
know each other better and sit down to (re)think on the way we work, where we
are heading and try to put some words on who we are and how we plan on moving
forward.&lt;/p&gt;

&lt;p&gt;You named it, we tried to define one of the obsessions in the startup culture:
company values. There are many pitfalls to avoid while doing so and any of them
can make the company look as a cliché, under-ambitious or reject some of the
stakeholders. Keep in mind that these values are publicly displayed or at least
talked about, which means your employees, investors and clients could all feel
disconnected from them. At best, their reaction would be
&amp;ldquo;whatever, I guess everybody says so&amp;rdquo; and see you as another cliché.&lt;/p&gt;

&lt;p&gt;At worst, they can reject the way you define yourself and consider the
advantages of working with you are not worth it.
But is the second scenario really worse? The scope of such problem is a lot
wider than your external communication and the &amp;ldquo;values&amp;rdquo; tab of your website.&lt;/p&gt;

&lt;p&gt;Using Paul Graham&amp;rsquo;s &lt;a href=&#34;http://www.paulgraham.com/growth.html&#34; target=&#34;_blank&#34;&gt;definition&lt;/a&gt;,
a startup is all about growth, hence moving
fast. Quick decisions and executions cannot come without breaking things and
building tension on the way. Trying to define values because they make you
sound confident while being agreeable by everyone cannot yield any outcome.
No great result comes out of willing to please everyone, and the corollary is
that &lt;strong&gt;every successful person and organization has haters&lt;/strong&gt;. Given this
statement, the best any entity can do is to choose who is likely not to stick
with them and why.&lt;/p&gt;

&lt;h2 id=&#34;why-values-anyway&#34;&gt;Why values anyway?&lt;/h2&gt;

&lt;p&gt;This question is totally legit, especially in countries like France where the
startup culture is still not familiar to a significant part of the population
or like Germany where pragmatism is king in both what you do and how you
communicate it.
Traditional organizations have always had a simple deal on the recruitment side:
lend me your skills and I&amp;rsquo;ll pay you decently. On the clients&amp;rsquo; side, the
&amp;ldquo;values&amp;rdquo; displayed were traditionally associated with product differentiation
(&amp;ldquo;at XYZ, our obsession is to bring the best product to [insert target] at
unbeatable prices&amp;rdquo;).
The shareholders&amp;rsquo; side did not even need big words, a couple KPIs from the last
quarter would do. As &lt;a href=&#34;https://medium.com/@Nicolas_Colin&#34; target=&#34;_blank&#34;&gt;Nicolas Colin&lt;/a&gt; phrases
in several Medium posts, keeping what is being said to each of these
stakeholders completely separated is not possible anymore in the digital age.
That&amp;rsquo;s partly why company&amp;rsquo;s culture and values became central topics.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve seen two cases at traditional companies. The first situation is ignorance
or non-existence of company values, maybe some of these will sound familiar:
&lt;em&gt;&amp;ldquo;Values? No this is the communication staff&amp;rsquo;s business&amp;rdquo;&lt;/em&gt;
&lt;em&gt;&amp;ldquo;We&amp;rsquo;re not here to dream, we&amp;rsquo;re paid to get the job done&amp;rdquo;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The second attitude is picking up &amp;ldquo;values&amp;rdquo; corresponding to trends but
completely disconnected from the organization&amp;rsquo;s reality. Just visit the
&lt;a href=&#34;http://cbsg.sf.net&#34; target=&#34;_blank&#34;&gt;Corporate bullshit generator&lt;/a&gt; and you will know what I&amp;rsquo;m
referring to:
We&amp;rsquo;ve all seen extremely conservative companies call themselves &amp;ldquo;innovators&amp;rdquo;
or some historical monopolists call themselves &amp;ldquo;disruptive&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;So what changed with startups? Simple, you can redefine the way your market
works (and sometimes create it in the process) and become the central element
for it. That&amp;rsquo;s an idea you can genuinely believe in, work for and something you
can promise employees, shareholders and clients.
Now where are your values in this? Simply where you want the market to go and
the path you&amp;rsquo;re ready to take to go there.&lt;/p&gt;

&lt;p&gt;There are obviously other factors at stake here, the fact that millennials
need to define themselves through what they do for instance and cannot just
work for a decent paycheck in the same polite colleague relation for 40+ years.
More than ever, our generation needs some sense in what we do at the moment and
not in a 40-year projection.&lt;/p&gt;

&lt;h2 id=&#34;writing-down-values-is-about-choosing-a-path-and-sticking-to-it&#34;&gt;Writing down values is about choosing a path and sticking to it&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;d say this is the main highlight I got from hours of thoughts about the topic
of company values. &lt;strong&gt;Choosing values is not about sounding cool&lt;/strong&gt;, not about
the image you want for the organization&amp;rsquo;s recruitments.&lt;/p&gt;

&lt;p&gt;Something concrete? Don&amp;rsquo;t define yourself as hackers if you spend at least as
much time planning as actually trying and building stuff. Don&amp;rsquo;t pretend to
disrupt anything if you&amp;rsquo;re playing the old rules within a known and stable
market. Don&amp;rsquo;t define yourself as transparent if you&amp;rsquo;re not obsessed with
everyone knowing both how you think and operate.&lt;/p&gt;

&lt;p&gt;Defining yourself through the most trendy terms of the year has lead to a
feeling of emptiness in the messages carried in the startup ecosystems and has
even become one of its
&lt;a href=&#34;http://blog.caranddriver.com/2016-consumer-electronics-show-cutting-through-the-buzzwords-to-what-really-matters/&#34; target=&#34;_blank&#34;&gt;clichés&lt;/a&gt;
or even &lt;a href=&#34;https://www.youtube.com/watch?v=J-GVd_HLlps&#34; target=&#34;_blank&#34;&gt;jokes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-to-define-your-company-in-a-non-cliché-way&#34;&gt;How to define your company in a non-cliché way&lt;/h2&gt;

&lt;p&gt;I won&amp;rsquo;t have the pretension to set the rules on this point, simply to match
some great frameworks from people smarter than me who gave this point
&lt;a href=&#34;https://www.youtube.com/watch?v=MpVCQfImQ1A&#34; target=&#34;_blank&#34;&gt;years of thoughts&lt;/a&gt;
(conference in French by Oussama Ammar) with the annoying points we discussed.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start with the hard way: define the cool things you are not. This goes with
a conclusion drawn earlier, every successful organization has haters, but don’t
get the cause-effect relation wrong: your company is not going to reach its
goals once it has haters. It should have haters because it defined a clear path
to success which induced not satisfying every stakeholder on the way. The
corollary is even a stronger conclusion: trying to please every potential
target and stakeholder is the safest way to getting stuck and unable to make
any decision. This is a luxury startups cannot afford by definition. Immobility
can only be explainable in traditional and established businesses.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Define your values on the fly: just like you don’t decide as a child that
you are a nice person, you don’t decide as a company that you are disrupters
before living it. Discover your organization as you are working together and
reaching the first painful milestones, these key steps in your development when
you have to decide where priorities are being set and who is not going to
remain supportive afterwards. These tough experiences and the retrospective
understanding of your reaction as a team will make you more confident in what
you are doing and help cut the fluff on things you are not meant to do.
This is the focus everyone needs to move faster and sharper than the
competition, the market and the context.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Functional and parallel PageRank implementation in Scala</title>
      <link>https://mbesancon.github.io/post/2016-09-13-page-rank/</link>
      <pubDate>Tue, 13 Sep 2016 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-09-13-page-rank/</guid>
      <description>

&lt;p&gt;When I &lt;a href=&#34;https://mbesancon.github.io/posts/2016-08-11-back-to-startup/&#34;&gt;came back to Equisense&lt;/a&gt;,
I was surprised and intrigued by many things. But there was one element of the
job in particular I had not planned: coming back to low level and embedded
programming from higher abstractions I was used to. No OS, no
libraries, no smooth write-and-test work-flow, just brutal and bare metal.
I clearly needed to blow some steam off with something closer to what I
usually do (or did), a data-driven and functional project using nice techs.&lt;/p&gt;

&lt;h2 id=&#34;why-yet-another-pagerank&#34;&gt;Why yet another PageRank?&lt;/h2&gt;

&lt;p&gt;The time came to find a new side project and I was just finishing the lectures
of &lt;a href=&#34;https://www.coursera.org/learn/parprog1&#34; target=&#34;_blank&#34;&gt;Parallel Programming&lt;/a&gt;, which I
recommend if you&amp;rsquo;re already at ease with Scala and its environment (IDEs, SBT).
I wanted to apply the concepts on a project built from scratch. One day,
while neglectfully scrolling through another blog post showing the basic
concepts of the PageRank computation, I thought this would make a &amp;ldquo;okay&amp;rdquo; project.
But wait, interesting elements here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The model behind the PageRank computation is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain&#34; target=&#34;_blank&#34;&gt;Markov Chain&lt;/a&gt;,
with which I have been working a lot with at Siemens.&lt;/li&gt;
&lt;li&gt;Iterating until stability of the ranks is basically a linear flow, easily
performed by &lt;a href=&#34;https://en.wikipedia.org/wiki/Tail_call&#34; target=&#34;_blank&#34;&gt;tail call recursion&lt;/a&gt;
which is optimized to avoid stack-overflowing the JVM by behaving like a &lt;code&gt;while&lt;/code&gt; loop.&lt;/li&gt;
&lt;li&gt;Computing the rank of each site is independent of the other computations,
parallelizing the tasks is a piece of cake&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we&amp;rsquo;re all set up for a purely functional and parallel PageRank.&lt;/p&gt;

&lt;h2 id=&#34;the-pagerank-model&#34;&gt;The PageRank model&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re gonna go through the basic implementation of the algorithm. What
fascinates me is the two-sided view of the algorithm: the intuitive version can
be explained to a 5-year-old (or to your boss) while the maths behind it
relies on the interpretation of matrix eigenvalues and on a computation of the
stationary distribution of the Markov model.&lt;/p&gt;

&lt;h3 id=&#34;the-intuitive-version&#34;&gt;The intuitive version&lt;/h3&gt;

&lt;p&gt;Imagine you&amp;rsquo;re surfing on the web like any productive Sunday evening. On a
given page, there is an equal probability to click on any link present on the
page. There is also a probability that you get tired of the current series of
pages and randomly go back to any page of the network.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s try to visualize the two extremes of this &amp;ldquo;random switch&amp;rdquo; usually called
&lt;em&gt;damping factor&lt;/em&gt; &lt;code&gt;d&lt;/code&gt;. If we set &lt;code&gt;d=0&lt;/code&gt;, the transition to any page is equally
probable, since the surfer will always switch to choosing a page at random.
This means that the links going out of the page they&amp;rsquo;re currently on don&amp;rsquo;t
influence the probability distribution of the next page.&lt;/p&gt;

&lt;p&gt;On the other end of the spectrum if the damping factor &lt;code&gt;d=1&lt;/code&gt;, the surfer will
always look for its next page in the outgoing links of her current page
(this raises an issue for pages without any links). An usual value for the
factor is &lt;code&gt;d=0.85&lt;/code&gt;which keeps the probability of long sequences of related pages
likely to happen, but allows for random switch.&lt;/p&gt;

&lt;h3 id=&#34;key-elements-of-the-algorithm&#34;&gt;Key elements of the algorithm&lt;/h3&gt;

&lt;p&gt;The algorithm uses the matrix of links: an entry &lt;code&gt;(i,j)&lt;/code&gt; is 1 if there is a
link on the page &lt;code&gt;j&lt;/code&gt; to the page &lt;code&gt;i&lt;/code&gt; and 0 otherwise (note that this notation
is opposite to the common convention for Markov transition matrices, where the
line is the origin state and the column the destination). The other element is
a rank vector which is updated until a convergence criterion is met.&lt;/p&gt;

&lt;h3 id=&#34;types-of-the-different-structures&#34;&gt;Types of the different structures&lt;/h3&gt;

&lt;p&gt;Since we want to be able to perform some computations in parallel, most
functions will manipulate Scala&amp;rsquo;s &lt;em&gt;Generic&lt;/em&gt; data structures. Let&amp;rsquo;s start with
the link matrix. It is a sparse structure: instead of representing all
entries of the matrix in a vector of vectors, just non-empty elements and
there corresponding column and line indexes are stored.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;// defining a dense matrix of Ints as a sequence of sequence&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;DenseMatrix&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #00AA88; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]]&lt;/span&gt;
&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;// SparseMatrix: tuple (line, column, value)&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;SparseMatrix&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #00AA88; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[(&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, the values of our link matrix only contains zeros and ones, so the
entries present in the structure all have one as value, so we just need to keep
rows and columns:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;LinkMat&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #00AA88; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[(&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The ranks are stored in a simple generic float sequence:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;R&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also need a few utility functions. &lt;code&gt;sumElements&lt;/code&gt; takes the matrix, the rank
vector and an integer to find all links for which the outgoing page is &lt;code&gt;j&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; sumElements&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;],&lt;/span&gt; A&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt; j&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;// sums all PageRanks / number of links for a column j&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; totalLinks &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; A&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;filter&lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;tup &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&amp;gt;&lt;/span&gt; tup&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_2 &lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt; j&lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;totalLinks&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;isEmpty&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;
    sys&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;error&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;No link in the page &amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; j &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot; at sumElements&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;else&lt;/span&gt;
    R&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;j&lt;span style=&#34;color: #555555&#34;&gt;)/&lt;/span&gt;totalLinks&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;size
&lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; This implementation of the function is not purely functional since
an imperative system error is raised if no index i is found. A better solution
here would have been to wrap the value in an &lt;code&gt;Option[Float]&lt;/code&gt;, return &lt;code&gt;None&lt;/code&gt; if no
index has been found and &lt;code&gt;Some(x)&lt;/code&gt; in case of success.&lt;/p&gt;

&lt;p&gt;We also need to find all pages pointing to a given page i. This might be a
bit compact, but keep in mind that the matrix is simply a pair of page indexes.
So we find all pages where the first element is i (the page the link is going
to), that&amp;rsquo;s the filter part. We then take the second element of the tuple, so
all indexes pointing to i, thanks to a map.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; findConnected&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt; A&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt;
  A&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;filter&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;_&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;i&lt;span style=&#34;color: #555555&#34;&gt;).&lt;/span&gt;map&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;_&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color: #555555&#34;&gt;).&lt;/span&gt;toSeq
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the result is returned as a normal sequence (not the generic version
allowing for parallel computation). It&amp;rsquo;s not a big deal since the resulting
sequence is always manageable compared to the whole graph we are manipulating.&lt;/p&gt;

&lt;p&gt;Now, we stated that the algorithm recurses on the rank of all pages until
stability, which is something we define through a &lt;code&gt;converged&lt;/code&gt; function. We
simply use a squared difference between two different versions of the rank to
determine if they are acceptably close and yield a boolean.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; converged&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;r1&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;],&lt;/span&gt; r2&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;],&lt;/span&gt; eps&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Boolean&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; totSquare&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; r1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;zip&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;r2&lt;span style=&#34;color: #555555&#34;&gt;).&lt;/span&gt;map&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;p&lt;span style=&#34;color: #555555&#34;&gt;=&amp;gt;(&lt;/span&gt;p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color: #555555&#34;&gt;)*(&lt;/span&gt;p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color: #555555&#34;&gt;)).&lt;/span&gt;sum
  sqrt&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;totSquare&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;r1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;size&lt;span style=&#34;color: #555555&#34;&gt;)&amp;lt;=&lt;/span&gt;eps
&lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that everything is set, the master piece becomes a piece of cake.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #9999FF&#34;&gt;@tailrec&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; compRank&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;],&lt;/span&gt; A&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;
                      damp&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt; eps&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;
                      niter&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;
                      niterMax&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;10000&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; rankIndex&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt; until R&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;size
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; rightRank&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; rankIndex map&lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;i&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; connected &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; findConnected&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;A&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;
    connected&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;map&lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;j&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #007788; font-weight: bold&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;=&amp;gt;&lt;/span&gt; sumElements&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt; A&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt; j&lt;span style=&#34;color: #555555&#34;&gt;)}.&lt;/span&gt;sum
  &lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;val&lt;/span&gt; newRank &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;=&lt;/span&gt; rightRank map &lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;damp&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;damp&lt;span style=&#34;color: #555555&#34;&gt;)/&lt;/span&gt;R&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;size&lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;converged&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;newRank&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;R&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;eps&lt;span style=&#34;color: #555555&#34;&gt;))&lt;/span&gt; newRank
  &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;niter&lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;=&lt;/span&gt;niterMax&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;{&lt;/span&gt;
    println&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Max iteration reached&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;
    newRank
  &lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;else&lt;/span&gt; compRank&lt;span style=&#34;color: #555555&#34;&gt;(&lt;/span&gt;newRank&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;A&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;damp&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;eps&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;niter&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;,&lt;/span&gt;niterMax&lt;span style=&#34;color: #555555&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #555555&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We first compute the right term of the new rank formula &lt;code&gt;rightRank&lt;/code&gt; and plug it
in &lt;code&gt;newRank&lt;/code&gt;. The two vectors can be passed to &lt;code&gt;compare&lt;/code&gt; to determine if
&lt;code&gt;newRank&lt;/code&gt; can be returned as a final result or if further recursion is needed.
A recursion counter also avoids waiting too long for a result and warns in case
of maximum recursion reached by printing to the standard output.
Once again, a more functional way would have been to wrap the result in a
&lt;code&gt;Try&lt;/code&gt; monad (no panic, we&amp;rsquo;re NOT going to go through monads, we&amp;rsquo;ve lost enough
people with this).&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ve surely noticed the &lt;code&gt;@tailrec&lt;/code&gt; tag highlighting that this function is not
going to blow the stack up.&lt;/p&gt;

&lt;h2 id=&#34;result-on-a-study-case&#34;&gt;Result on a study case&lt;/h2&gt;

&lt;h3 id=&#34;the-enron-email-dataset&#34;&gt;The Enron email dataset&lt;/h3&gt;

&lt;p&gt;While surfing in a semi-random way to find a cool dataset for the application,
I found the &lt;a href=&#34;https://snap.stanford.edu&#34; target=&#34;_blank&#34;&gt;SNAP&lt;/a&gt; project
from Stanford on which the
&lt;a href=&#34;https://snap.stanford.edu/data/email-Enron.html&#34; target=&#34;_blank&#34;&gt;Enron emails data&lt;/a&gt;
are presented and to be downloaded. If you look at the
&lt;a href=&#34;https://github.com/mbesancon/PageRank&#34; target=&#34;_blank&#34;&gt;Github repo&lt;/a&gt; for this project, I simply
removed the header from the txt file to make the parsing tasks easier.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;As many phenomena dealing with &lt;a href=&#34;https://en.wikipedia.org/wiki/Pareto_principle&#34; target=&#34;_blank&#34;&gt;concentration of resources&lt;/a&gt;,
the distribution of ranks follows a Pareto distribution, which can be
visualized on a log-log scale. I used Python with numpy and matplotlib, finding
the current Scala libraries still to cumbersome for this simple task. Here is
the result:
&lt;img src=&#34;https://mbesancon.github.io/img/posts/pageRank/rankDist.png&#34; alt=&#34;Resulting log-rank&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;a-conclusion-on-the-functional-imperative-debate&#34;&gt;A conclusion on the functional/imperative debate&lt;/h2&gt;

&lt;p&gt;If some of you clone and try to run the project (you&amp;rsquo;ll just need sbt for that).
Some people could argue that the runtime is too long for what it does (whatever
too long means), and that an imperative solution with a mutable rank on which
we loop until convergence. And I suppose they are right, but parallel
imperative is objectively a pain to work with. &lt;strong&gt;Tell the architecture what you
want, not what to do and it will compute it for you, whatever its
configuration is&lt;/strong&gt;, from your laptop to several clusters. That&amp;rsquo;s a key reason
why &lt;a href=&#34;http://spark.apache.org&#34; target=&#34;_blank&#34;&gt;Spark&lt;/a&gt; is functional for instance.&lt;/p&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>Back to startup life: thoughts after the first days</title>
      <link>https://mbesancon.github.io/post/2016-08-11-back-to-startup/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-08-11-back-to-startup/</guid>
      <description>

&lt;p&gt;In politics, a government&amp;rsquo;s first decisions and actions are often reviewed and
assessed after the famous first 100 days. According to &lt;a href=&#34;https://en.wikipedia.org/wiki/First_hundred_days&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;,
the term was coined by F. Roosevelt himself. I wanted to throw the first
thoughts on my comeback at Equisense, on culture and operations and the difference
between the two stages.&lt;/p&gt;

&lt;h2 id=&#34;startups-are-in-a-continuous-headlong-rush&#34;&gt;Startups are in a continuous headlong rush&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ll not wait the 100 days to write this post, because in a startup things move
faster, so why wait another month? At the same time you have to remain focused
for a lot longer than three months or the consequences to expect are worse than
skeptical articles or plunging opinion polls. Nobody could judge actions or
decisions drawn after a year in business based on one or even three months.&lt;/p&gt;

&lt;p&gt;And this adrenalined marathon does not (or should not) stop with a first product
release, or worse with a nice fund-raising round. This stops with the company
running out of business or the market saying &amp;ldquo;I love you, let&amp;rsquo;s stay forever
until death do us apart&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;an-early-insight-before-the-long-break&#34;&gt;An early insight before the long break&lt;/h2&gt;

&lt;p&gt;I had already worked with the team in June, July and August 2015 during their
three-founders-and-laptops stage. The focus was on first studies of acceleration
signals and feasibility of some features given technological and product choices.
Those first graphs and explanations thrown on a small Tex reports
were later improved and re-written by the team as it designed
&lt;a href=&#34;http://www.equisense.com/en/product.html&#34; target=&#34;_blank&#34;&gt;Motion&lt;/a&gt;. After these few months,
I left the startup for Montréal, where I spent my last semester as a student,
after which I carried out my Master project in Germany. When came the time to
think about what came next, we were still in contact with Camille, Idriss and
Benoit and the conversation shifted to how the project had evolved and the
thousand cool things coming in the next months and could become a &amp;ldquo;real job&amp;rdquo;
this time. After a couple more one-to-one, a few visits in Lille and a hackathon,
I was officially back on the adventure.&lt;/p&gt;

&lt;h2 id=&#34;getting-back-and-the-baby-is-all-grown-up&#34;&gt;Getting back and the baby is all grown up!&lt;/h2&gt;

&lt;p&gt;In the meantime, Equisense launched a successful Kickstarter, reinforcing the
feeling that horse-riders value what the product can bring to their experience.
The company moved from its first office in Compiègne Innovation Center to
the impressive Euratechnologies center in Lille.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/euratechnologies.jpg&#34; alt=&#34;Euratechnologies&#34; /&gt;
[1]&lt;/p&gt;

&lt;p&gt;More than this, the team also got bigger to face the challenges of this new
stage. The goal is no longer to hack horses acceleration signals until something
comes out of it, but to build a reliable and intuitive product from the
scientific findings and technological pieces brought together.&lt;/p&gt;

&lt;p&gt;Really getting on the market requires a deeper bond with horse-riders
and as much feedback as possible. The new team embodies these changes: a
diversity of mindsets, experiences and backgrounds to handle all upcoming
challenges with the same care for clients. The hacker spirit isn&amp;rsquo;t gone in
this new version of the company, but it isn&amp;rsquo;t the major pillar of the culture
anymore. A culture is hard to put into words, but I&amp;rsquo;d say this
second face of our Janus startup is a combination of a &lt;strong&gt;genuine care for
horses wellness and of a passion for horse-riding.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/newteam.png&#34; alt=&#34;The new team&#34; /&gt;
[2]&lt;/p&gt;

&lt;p&gt;The fact is that while I was admiring their external successes from my Canadian
home, (the Kickstarter campaign, new partnerships, features of the product
getting out of the ground one by one&amp;hellip;), the most impressive achievement was
being joined by so many diverse profiles while building a working environment
at the image of their horse-riders&amp;rsquo; mindset.&lt;/p&gt;

&lt;p&gt;The founders already had this care and passion in their DNA, they just
succeeded in transforming it into a full culture and transmitting it into an
obsession within the team.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/camille.png&#34; alt=&#34;Camille&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/benoit.png&#34; alt=&#34;Benoit&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/idriss.png&#34; alt=&#34;Idriss&#34; /&gt;&lt;/p&gt;

&lt;p&gt;[2]&lt;/p&gt;

&lt;h2 id=&#34;where-are-we-in-the-lifetime-from-a-clumsy-foal-to-the-great-stallion&#34;&gt;Where are we in the lifetime? From a clumsy foal to the great stallion&lt;/h2&gt;

&lt;p&gt;Other than the culture, the operations changed from the clumsy foal learning to
stay up on its hoofs to the stallion swiftly jumping and anticipating all
obstacles.
&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/foal.jpg&#34; alt=&#34;foal&#34; /&gt;
[3]&lt;/p&gt;

&lt;p&gt;The seed stage is about using all assets that are or can easily
be at your disposal to run tests and confirm hypotheses. Unlike lots of web
startups, uncertainty does not come only from the market, but also from
the technological bricks: &lt;strong&gt;hardware is today where the web was about ten years
ago&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Moving forwards meant iterating while building knowledge on both fields of
uncertainty. This meant at the same time assessing if some measured signals
could detect a jump during a training session, and if the customers actually
had an interest in the feature. Working for nothing can be frustrating, but
ignoring something horse-riders want would have been much worse!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/100Days/cso_fontainebleau.jpg&#34; alt=&#34;grown-up champ&#34; /&gt;
[5]&lt;/p&gt;

&lt;p&gt;In the new phase, uncertainty radically changed. In the first stage,
we saw how it was caused by a lack of knowledge on both the
technology and the market. Of course the knowledge the team has on
these topics is still not complete, but
&lt;strong&gt;is enough to make intelligent decisions and move on&lt;/strong&gt;. However, a
new source of uncertainty has replaced the two previous:&lt;/p&gt;

&lt;p&gt;Organization and processes are obvious when 4 people are working
together on several issues. They become fuzzy and chaotic when several
teams are working at high speed without being able to check on each
other all day long.&lt;/p&gt;

&lt;p&gt;The key issue is the company&amp;rsquo;s speed to deliver
without letting any randomness in the result. Equisense&amp;rsquo;s customers
are horse-riders willing to improve their experience, care and
efficiency, not hackers accepting a buggy beta with promising
features as long as the product has an API in their favorite language!&lt;/p&gt;

&lt;p&gt;Equisense changed a lot during my absence to evolve into one of the new
major phenomena in its industry. If I had to describe how it operates
now, I guess I&amp;rsquo;d highlight &lt;strong&gt;the focus, the acceleration and the
deterministic, well-defined outcome of a still random and flexible organization&lt;/strong&gt;.
(hope my data science buddies will tolerate the paradox of the last one).&lt;/p&gt;

&lt;p&gt;The coming months promise to be thrilling with the shipping of the first Motion
sensors, the R&amp;amp;D on improved features, new products and whatever else comes
out of the blue. Even though I&amp;rsquo;m still getting used to working with horses (photos
to come), I&amp;rsquo;m without a doubt excited to have rejoined these crazy riders, so
stay tuned!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Image sources:
[1] &lt;a href=&#34;http://www.lesechos.fr/politique-societe/regions/0203756306258-nord-pas-de-calais-a-lille-nait-la-silicon-valley-du-numerique-1043082.php&#34; target=&#34;_blank&#34;&gt;Les Echos: Nord - Pas-de-Calais : A Lille naît la « Silicon Valley » du numérique&lt;/a&gt;
[2] &lt;a href=&#34;www.equisense.com&#34; target=&#34;_blank&#34;&gt;Equisense website&lt;/a&gt;
[3] &lt;a href=&#34;http://www.eco121.fr/equisense-ouvre-la-voie-du-cheval-connecte/&#34; target=&#34;_blank&#34;&gt;http://www.eco121.fr/equisense-ouvre-la-voie-du-cheval-connecte/&lt;/a&gt;
[4] [5] Wikimedia&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On startup weekends and getting things done</title>
      <link>https://mbesancon.github.io/post/2016-07-11-hackathon/</link>
      <pubDate>Mon, 11 Jul 2016 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-07-11-hackathon/</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s monday morning and I&amp;rsquo;m waking up with a hangover sensation, not from
partying in the streets of Lille as one could think at the beginning of the
week, but from the last intense 48 hours. I took part in the so-called
&amp;ldquo;creathon&amp;rdquo; organized by the
&lt;a href=&#34;https://switchupchallenge.com/&#34; target=&#34;_blank&#34;&gt;Switch up challenge&lt;/a&gt; and
&lt;a href=&#34;makesense.org&#34; target=&#34;_blank&#34;&gt;MakeSense&lt;/a&gt;. The special touch on this event was the social
impact the projects were meant to have. The result could even not be a company
but a non-profit organization.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m going to generalize my thoughts as much as possible, but to give a
concrete view of what is going on, I&amp;rsquo;m going to use the example of &lt;strong&gt;Quare&lt;/strong&gt;,
the project we worked on. It is a device quantifying your stress and the quality
of your current working environment thanks to different sensors and
individually adjusted algorithms.&lt;/p&gt;

&lt;h2 id=&#34;building-a-company-from-the-ground-up-just-let-me-finish-this&#34;&gt;Building a company from the ground up: just let me finish this&lt;/h2&gt;

&lt;p&gt;Creating the whole concept for a scalable, repeatable and profitable business
based on an issue you want to tackle takes time, focus and creativity. The goal
is not to come up with the most spectacular way to solve the problem and build
your product, but to find the simplest way allowing your business to grow
without limits. &lt;strong&gt;You&amp;rsquo;re not building the Empire State, you&amp;rsquo;re planting an
acorn to grow an oak&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;stop-organizing-everything-mess-is-a-bless&#34;&gt;Stop organizing everything, mess is a bless&lt;/h2&gt;

&lt;p&gt;People coming from a business and management background tend to think of
activities in terms of processes, so a structured way in which things are
handled and operated. When designing the concept for a startup, just don&amp;rsquo;t.
The reason is, your team is going through several critical phases where any
constraint in the reasoning would hinder the ability to rephrase the problem
you&amp;rsquo;re focused on, or come up with a radical new way to address it. Just let
the mess happen and collectively feel when it is time to move on to a next step.
If a team member feels like you missed something, simply let them gather their
thoughts and arguments, then try to build on them and see how they change
the concept. However, not everything must be kept if you don&amp;rsquo;t want an
&lt;a href=&#34;https://medium.dave-bailey.com/how-to-reconnect-with-your-purpose-as-a-founder-6d18e80ccc9c#.j39hta9i6&#34; target=&#34;_blank&#34;&gt;over-generalized problem&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;focus-is-key-to-deliver&#34;&gt;Focus is key to deliver&lt;/h2&gt;

&lt;p&gt;This part is a bit tricky and you won&amp;rsquo;t find any silver bullet, even less in
this blog post. By focused, understand both being focus as state-of-mind and
keeping your business idea focused on what matters the most to the issue you
address: this is about making real choices which will never please everyone.
Keeping focused and moving fast during the week-end has two
effects. If you play well, &lt;strong&gt;you&amp;rsquo;ll deliver a lot more by the time of the final
pitch&lt;/strong&gt;, and that&amp;rsquo;s an awesome point if you have some of the following
objectives:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Convince and impress specific people in the room: potential partners, investors, accelerators&lt;/li&gt;
&lt;li&gt;Check how comfortable team members are with each other, if you align on your
ambition, your definition and perception of the problem, the way you work and
react under pressure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To relate things to our situation this weekend, we were an initial team of two
engineers working for a middle-stage startup and two designers at ease with both
product and graphical design. A highly motivated business school student joined
the team a bit later in the weekend. We had both a creative and chaotic
enthusiasm to explore the problems related to stress and lack of focus at work
(the issue we decided to tackle) and some ability to focus and to move fast
based on our diverse experiences and skills.&lt;/p&gt;

&lt;p&gt;We addressed the issue of focus at work which is our direct concern while
working in an open-space and dealing with creative work requiring long,
uninterrupted sessions to make the best out of a day.
Even though we spent a great deal of time defining the scope of the
problem and primary targets, we all had this &lt;em&gt;get things done&lt;/em&gt; attitude and
were eager to start realizing something concrete from the beginning. So not
only did we all have a strong link to the problem, we also had a common view on
it, it allowed the team to have a sharp vision and homogeneous of work and focus.&lt;/p&gt;

&lt;p&gt;But there are also several not-so-good reasons to move fast during a startup
weekend:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Validate technical choices (Should my device communicate through Wifi or
Bluetooth? What information do we need to store from our clients? &lt;strong&gt;Any&lt;/strong&gt;
back-end related question)&lt;/li&gt;
&lt;li&gt;Precise quantitative estimates are pointless. Yup, business plans don&amp;rsquo;t have
their place at a startup weekend, if they have a place at all for early stage
of uncertain and radically new businesses. Try to simply get some rough ideas
about the size of the problem, how much would the device cost in production.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, to relate this to our situation, we could make a pretty good estimate of
the Bill of Materials based on the sensors we wanted to use and on our
experience with Equisense (what components were needed, the type of
micro-controller, etc&amp;hellip;). We could come out with different shapes for the
device and test it thanks to different people giving feedback which allowed us
to iterate, but that was is. We did not go any further on the economic
projections, nor did we try to build the whole product in two days. Okay maybe
we prototyped the product with an Arduino and the appropriate sensors. That was
clearly unnecessary for the weekend, but still fun to
&lt;a href=&#34;https://twitter.com/SophieDuveau/status/795248595301703681&#34; target=&#34;_blank&#34;&gt;play around&lt;/a&gt; with
hardware and show what anyone can do with a board, two sensors and some cables.&lt;/p&gt;

&lt;p&gt;Nonetheless, one of the team&amp;rsquo;s designers bought an Arduino kit right after the
weekend, a business student decided to go further with one of his personal
projects after seeing how much we had got done after two days.
Even if we don&amp;rsquo;t build the next unicorn, discovering each other&amp;rsquo;s fields and
building a common culture in so little time was in itself a success and a
learning experience.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bringing data science to engineers</title>
      <link>https://mbesancon.github.io/post/2016-05-21-bringing-data-science-engineers/</link>
      <pubDate>Sat, 21 May 2016 00:00:00 -0400</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-05-21-bringing-data-science-engineers/</guid>
      <description>

&lt;p&gt;The goal of this article is to present couple challenges waiting the industrial
data scientist or industrial data science teams, the deep reasons I believe are
the root of this inertia, based on my experience (in both data science and
engineering projects) and exchanges with engineers and data scientists. The
last part introduces some suggestions to make the collaboration richer for
both sides.&lt;/p&gt;

&lt;h2 id=&#34;why-isn-t-data-science-already-everywhere-in-engineering&#34;&gt;Why isn&amp;rsquo;t data science already everywhere in engineering?&lt;/h2&gt;

&lt;p&gt;It is surprising that this transition hasn&amp;rsquo;t been so spontaneous. Indeed, one
could think that engineers, belonging to the &amp;ldquo;STEM family&amp;rdquo; (people studying or
working in fields related to Science, Technology, Engineering and Mathematics)
would easily embrace the concepts and methods of data science and moreover be
able to identify the potential gains, savings and improvements to carry out
complex projects in a more effective manner.&lt;/p&gt;

&lt;h3 id=&#34;silo-thinking-in-stem&#34;&gt;Silo thinking in STEM&lt;/h3&gt;

&lt;p&gt;That&amp;rsquo;s not the case, most engineers I&amp;rsquo;ve been discussing and working with never
considered these techniques as relevant to their current tasks. So why so
little enthusiasm? A recurrent problem I noticed is the silo thinking of
disciplines created by strong and early specializations, along with natural
distaste and reduction of unknown fields.&lt;/p&gt;

&lt;h3 id=&#34;we-re-not-google-deal-with-it&#34;&gt;We&amp;rsquo;re not Google, deal with it&lt;/h3&gt;

&lt;p&gt;So when someone will first pitch machine learning to an engineer, I would often
observe reactions of &amp;ldquo;it&amp;rsquo;s not relevant to my field/work/issues&amp;rdquo; because they
don&amp;rsquo;t consider being in a &amp;ldquo;tech&amp;rdquo; industry. This is the same reaction type
observed in companies facing digital disruption (see the excellent article of
Nicolas Colin
&lt;a href=&#34;http://www.thefamily.co/hot-news/the-five-stages-of-denial&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;As a personal example, as I was talking to a production manager about the
impact advanced predictive analytics could have on machine reliability and
availability, she advanced the &amp;ldquo;non-tech&amp;rdquo; argument, to which I answered with
examples of traditional manufacturing companies already using these techniques,
including General Electric for turbine monitoring (what they refer to as the
Industrial Internet). His last point was &amp;ldquo;Well sure but&amp;hellip; we&amp;rsquo;re not GE&amp;rdquo;, which
I understood as &amp;ldquo;I&amp;rsquo;m not able to learn from nor to work in that field totally
out of my comfort zone&amp;rdquo;. Although, her discomfort with the methods involved is
easily understandable since it requires key concepts in mathematics, statistics
and algorithm thinking which would often be considered as theory unusable in
their &amp;ldquo;real life&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&#34;my-subject-is-so-complex&#34;&gt;My subject is so complex&lt;/h3&gt;

&lt;p&gt;The other reaction one would observe is linked to an interesting thinking
process: People always tend to reduce the breadth of subjects they don&amp;rsquo;t know,
and to emphasize (not to say oversize) the width and complexity of their own
domain. I recently read a &amp;ldquo;conversation hack&amp;rdquo; to make a conversation pleasant
to someone, in three steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Ask them what they do for a living&lt;/li&gt;
&lt;li&gt;Ask them some more details about how they manage things&lt;/li&gt;
&lt;li&gt;Look impressed, add &amp;ldquo;Wow, that sounds very complex&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;People don&amp;rsquo;t feel at ease with the introduction of quantitative, rational
methods and analytics for decision-making in their daily work because this
implies that a rather &amp;ldquo;simple&amp;rdquo; model can generate better decisions than them.
It revives this old phobia of losing their job to a machine.&lt;/p&gt;

&lt;h3 id=&#34;but-still-why-particularly-engineers&#34;&gt;But still&amp;hellip; why particularly engineers?&lt;/h3&gt;

&lt;p&gt;We didn&amp;rsquo;t address this question yet, and it still sounds counter-intuitive,
given our first statements. From my personal experience studying and working
with both junior and senior engineers, and relatively to business or social
science background, there is a stronger will to &amp;ldquo;master the model&amp;rdquo; and
understand most key aspects of the system they work on.&lt;/p&gt;

&lt;p&gt;Bank managers, marketing leaders or finance analysts totally feel comfortable
with the use of data base systems and business intelligence tools, even
statistical analyses or predictive modeling tools they can perfectly leverage,
but not often understand on the technical parts. They would just need to be
able to read, use and trust the results. Engineers, on the other hand don&amp;rsquo;t
feel legitimate when using tools they don&amp;rsquo;t master they feel the need of
understanding and controlling what&amp;rsquo;s going on under the hood.&lt;/p&gt;

&lt;p&gt;There is a common vision of the engineers in several cultures, they are the
handy people, able to answer most of your questions, master all techniques from
nuclear power generation to biotechnologies. They are all supposed to be Tony
Stark (or Elon Musk in a more realistic way). So their secret fear is not about
being afraid of getting their job &amp;ldquo;automated&amp;rdquo; but more about a situation where
they cannot handle their system anymore because a part of the decisions taken
is not under their control anymore.&lt;/p&gt;

&lt;h2 id=&#34;what-to-do-about-it&#34;&gt;What to do about it?&lt;/h2&gt;

&lt;h3 id=&#34;what-data-science-can-bring-to-their-organization&#34;&gt;What data science can bring to their organization&lt;/h3&gt;

&lt;p&gt;Proving the utility of data science is the easy part, the process is actually
almost identical to bringing data science to any other industry. The potential
users should be shown what pain points this new field would address in their
business, how similar businesses have already applied machine learning to
their issues, and how the processes should be adapted to these projects.&lt;/p&gt;

&lt;h3 id=&#34;how-it-actually-works&#34;&gt;How it actually works&lt;/h3&gt;

&lt;p&gt;Empowering the engineers through explanations of the key concepts might be
seemingly pointless and time-consuming, but helps them accepting the
techniques involved as a part of the &amp;ldquo;internal model&amp;rdquo; secretly hidden in each
engineer&amp;rsquo;s mind and used to think about their system and make decisions upon
it.&lt;/p&gt;

&lt;p&gt;Most engineers are usually used to (at least) basic algorithm structures. So
using it to make them understand the thinking pattern behind machine learning
may help them to understand the mechanisms and feel at ease with reapplying
it. Once you&amp;rsquo;ve covered the fundamentals, a modeling skill should be
developed. Indeed, being able to model a problem as a data science project
will give a pretty straightforward beginning (especially on variable
selections or feature engineering).&lt;/p&gt;

&lt;p&gt;Basic linear regression (and in general other curve fitting methods) have
already been seen for experimental purposes in most engineering fields. If one
has only time to explain key concepts, I would give the following order:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Classification principles, example of classification trees.&lt;/li&gt;
&lt;li&gt;Regression techniques (if not already known). Simple and multivariate linear regression, polynomial regression.&lt;/li&gt;
&lt;li&gt;Unsupervised learning, example of k-means clustering.&lt;/li&gt;
&lt;li&gt;Overfitting, cross-validation concept and techniques.&lt;/li&gt;
&lt;li&gt;Ensemble learning, example of random forests.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With clear but complete explanations of regression, classification and
unsupervised learning, along with a previous knowledge of regression
techniques, most engineers will be able to identify opportunities to get
deeper insights into the phenomena they investigate or to build robust
predictions through machine learning, which is the basic goal to break the
barriers we discussed. The 4th and 5th topics are a bonus allowing them to
understand what techniques data scientists would use, they would not need them
for opportunity identification but to extend their &amp;ldquo;internal model&amp;rdquo;, which can
only be beneficial.&lt;/p&gt;

&lt;h3 id=&#34;key-examples&#34;&gt;Key examples&lt;/h3&gt;

&lt;p&gt;These examples are taken from diverse projects, challenges and data sets
including some personal ones. Each case study is addressed to specific targets.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Process, Energy and Chemical Engineers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I studied once the Combined Cycle Power Plant dataset which can be found on
the UCI dataset repository here. Using machine learning allowed the research
group not to work on the basis of restrictive hypotheses on the thermodynamic
behavior of the gas or steam, nor on the heat exchange and fluid mechanics
phenomena involved (e.g. pressure drop in the pipes due to phase change). The
predictions based on data are a totally new way to combine formal model-based
approaches (including process optimization) and operational realities (the
good old &amp;ldquo;gut feeling&amp;rdquo; experienced staff will tell you about).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Biomedical Engineers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This also includes all high-level medical professions. Well-known applications
were found in several fields, including pattern recognition from medical
images and data, disease risk estimations from patient background
information.&lt;/p&gt;

&lt;p&gt;Predictive modeling systems will be a decisive disruption in physicist work,
they replace the human decision-making process, based on few variables and on
a biased and relative experience with the risk-based optimal decision backed
by millions of data points.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Industrial, Manufacturing and Quality Engineers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Those case studies are inspired by my personal experience and the solutions
offered by several software development companies.&lt;/p&gt;

&lt;p&gt;The first one is the application of classification trees to replace rules
defining the quality of a product (first, second class or discarded for
instance). Using proper data mining tools allows the production manager to
define the relative &amp;ldquo;cost&amp;rdquo; of false positives (good products declared as not
salable, which induces all the manufacturing costs without the revenue) and
false negatives (non-conform products sent to be sold, which induces a risk of
complaint, on operation product default, image issues or recall campaigns).&lt;/p&gt;

&lt;p&gt;The second example is combining time-series analysis and multi-variable
regression techniques to give risk estimations on the process stability and
trends. I observed several software solution providers to whom the transition
from statistics to predictive modeling was a simple and obvious evolution.&lt;/p&gt;

&lt;p&gt;Bringing machine learning to engineers is a challenge and must be considered
as a promising step for both data science and engineering. Formal modeling
approaches and experimental considerations will eventually be able to be
conciliated. Data science will gain a significant support and become an
accelerator for the development of new techniques.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;re an engineer, a data scientist? Have you ever experienced collaborating
with engineers on data science applications? Did you encounter some
difficulties specific to working with engineers? Please get in touch for
further discussion on these topics.&lt;/p&gt;

&lt;p&gt;Now that we have discussed what data science could bring to engineers, a
second article may come to explain how to build a predictive model from
scratch in an industrial context.&lt;/p&gt;

&lt;p&gt;Special thanks to Robert, Benoit and Florian for their feedback on the article.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part III</title>
      <link>https://mbesancon.github.io/post/2016-01-13-fraud-detection3/</link>
      <pubDate>Wed, 13 Jan 2016 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-01-13-fraud-detection3/</guid>
      <description>

&lt;p&gt;[1]&lt;/p&gt;

&lt;p&gt;Part III: Model development&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To follow the following article without any trouble, I would recommend to
start with the beginning.&lt;/p&gt;

&lt;h1 id=&#34;how-does-predictive-modeling-work&#34;&gt;How does predictive modeling work&lt;/h1&gt;

&lt;h2 id=&#34;keep-the-terminology-in-mind&#34;&gt;Keep the terminology in mind&lt;/h2&gt;

&lt;p&gt;This is important to understand the principles and
sub-disciplines of machine learning. We are trying to predict a specific
&lt;strong&gt;output&lt;/strong&gt;, our information of interest, which is the category of bank note
we observe (genuine or forged).
This task is therefore labeled as &lt;strong&gt;supervised learning&lt;/strong&gt;, as opposed to
&lt;strong&gt;unsupervised learning&lt;/strong&gt; which consists of finding patterns or groups from
data without a priori identification of those groups.&lt;/p&gt;

&lt;p&gt;Supervised learning can further be labeled as &lt;strong&gt;classification&lt;/strong&gt; or
&lt;strong&gt;regression&lt;/strong&gt;, depending on the nature of the outcome, respectively
categorical or numerical. It is essential to know because the two disciplines
don&amp;rsquo;t involve the same models. Some models work in both cases but their expected
behavior and performance would be different. In our case, the outcome is
categorical with two levels.&lt;/p&gt;

&lt;h2 id=&#34;how-does-classification-work&#34;&gt;How does classification work?&lt;/h2&gt;

&lt;p&gt;Based on a subset of the data, we train a
model, so we tune it to minimize its error on these data. To make a parallel
with Object-Oriented Programming, the model is an &lt;strong&gt;instance&lt;/strong&gt; of the
class which defines how it works. The attributes would be its parameters and
it would always have two methods (functions usable only from the object):
* &lt;strong&gt;train&lt;/strong&gt; the model from a set of observations (composed of predictive
    variables and of the outcome)
* &lt;strong&gt;predict&lt;/strong&gt; the outcome given some new observations
Another optional method would be &lt;strong&gt;adapt&lt;/strong&gt; which takes new training data and
adjusts/corrects the parameters. A brute-force way to perform this is to call
the train method on both the old and new data, but for some models a more
efficient technique exists.&lt;/p&gt;

&lt;h2 id=&#34;independent-evaluation&#34;&gt;Independent evaluation&lt;/h2&gt;

&lt;p&gt;A last significant element: we mentioned using only a subset of the data to
train the model. The reason is that the performance of the model has to be
evaluated, but if we compute the error on the training data, the result will
be biased because the model was precisely trained to minimize the error on this
training set. So the evaluation has to be done on a separated subset of the
data, this is called &lt;strong&gt;cross validation&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&#34;our-model-logistic-regression&#34;&gt;Our model: logistic regression&lt;/h1&gt;

&lt;p&gt;This model was chosen mostly because
it is visually and intuitively easy to understand and simple to
implement from scratch.
Plus, it covers a central topic in data science, optimization.
The underlying reasoning is the following:
The logit function of the probability of a level of the classes is
linearly dependent on the predictors. This can be written as:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;log(p&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;p)) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; beta0 &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; beta[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; beta[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why do we need the logit function here?
Well technically, a linear regression could be fitted with the class as output
(encoded as 0/1) and the features as predictive variables. However, for some
values of the predictors, the model would yield outputs below 0 or above 1.
The logistic function &lt;strong&gt;equation&lt;/strong&gt; yields an output between 0 and 1 and
is therefore well suited to model a probability.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/linear_binary.png&#34; alt=&#34;Linear regression on binary output&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/logistic_binary.png&#34; alt=&#34;Logistic regression on binary output&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can noticed a decision boundary, which is the limit between the
region where the model yields a prediction &amp;ldquo;0&amp;rdquo; and a prediction &amp;ldquo;1&amp;rdquo;.
The output of the model is a probability of the class &amp;ldquo;1&amp;rdquo;, the forged
bank notes, so the decision boundary can be put at p=0.5, which would be
our &amp;ldquo;best guess&amp;rdquo; for the transition between the two regions.&lt;/p&gt;

&lt;h2 id=&#34;required-parameters&#34;&gt;Required parameters&lt;/h2&gt;

&lt;p&gt;As you noticed in the previous explanation, the model takes a vector of
parameters which correspond to the weights of the different variables.
The intercept \beta_0 places the location of the point at which p=0.5,
it shifts the curve to the right or the left.
The coefficients of the variables correspond to the sharpness of the transition.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/logistic_coeff.png&#34; alt=&#34;Evolution of the model with different coefficient values&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;learning-process&#34;&gt;Learning process&lt;/h2&gt;

&lt;h3 id=&#34;parameters-identification-issue&#34;&gt;Parameters identification issue&lt;/h3&gt;

&lt;p&gt;Unlike linear regression, the learning process for logistic regression is not
a straight-forward computation of the parameters through simple linear algebra
operations. The criterion to optimize is the likelihood, or equivalently, the
log-likelihood of the parameters:&lt;/p&gt;

&lt;!-- \mathscr{L}(\beta|(X,Z)) = f_{\beta}\left(X=x,Z=z\right) --&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;L(beta&lt;span style=&#34;color: #555555&#34;&gt;|&lt;/span&gt;(X,z)) &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; f(X,z)
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&#34;parameters-update&#34;&gt;Parameters update&lt;/h3&gt;

&lt;p&gt;The best parameters in the sense of the log-likelihood are therefore found
where this function reaches its maximum.
For the logistic regression problem,
there is only one critical point, which is also the only maximum of the
log-likelihood. So the overall process is to start from a random set of
parameters and to update it in the direction that increases the
log-likelihood the most. This precise direction is given by the
&lt;strong&gt;gradient&lt;/strong&gt; of the log-likelihood. The updated weights at each iteration
can be written as:&lt;/p&gt;

&lt;!-- \beta^{(n+1)} = \beta^{(n)} + \gamma^{(n)}\nabla(log(\mathscr{L}(\beta^{(n)}))) --&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;beta &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; beta &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; gamma&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; gradient_log_likelihood(beta)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Several criteria can be used to determine if a given set of parameters is an
acceptable solution. A solution will be considered acceptable when the
difference between two iterations is low enough.&lt;/p&gt;

&lt;h3 id=&#34;optimal-learning-rate&#34;&gt;Optimal learning rate&lt;/h3&gt;

&lt;p&gt;The coefficient gamma is called the &lt;strong&gt;learning rate&lt;/strong&gt;. Higher values lead to
quicker variations of the parameters, but also to stability and convergence
issues. Too small values on the other increase the number of steps required to
reach an acceptable maximum. The best solution is often a varying learning
rate, adapting the rate of variations. The rate at step n is chosen as follows:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;gamma_n &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; alpha&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color: #336666&#34;&gt;min&lt;/span&gt;(c0,&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;sqrt(n)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Which means that the learning rate is constant for all first steps until the
following condition is reached:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;n &lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;c0)&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;c0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After this iteration, the learning rate slowly decreases because we assume the
parameters are getting closer to the right value, which we don&amp;rsquo;t want to
overshoot.&lt;/p&gt;

&lt;h2 id=&#34;decision-boundaries-and-2d-representation&#34;&gt;Decision boundaries and 2D-representation&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;decision region&lt;/strong&gt; is the subset of the features space within which the
decision taken by the model is identical. A &lt;strong&gt;decision boundary&lt;/strong&gt; is the
subset of the space where the decision &amp;ldquo;switches&amp;rdquo;. For most algorithms,
the decision taken on the boundary is arbitrary. The possible boundary
shapes are a key characteristic of machine learning algorithms.&lt;/p&gt;

&lt;p&gt;In our case, logistic regression models the logit of the probability,
which is strictly monotonous with the probability as linearly
proportional to the predictors. It can be deduced that the decision
boundary will be a straight line separating the two classes.
This can be visualized using two features of the data, &amp;ldquo;vari&amp;rdquo; and
&amp;ldquo;k_resid&amp;rdquo;:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;w &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; learn_weights(data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;iloc[:,(&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;)])

&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# building the mesh&lt;/span&gt;
xmesh, ymesh &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;meshgrid(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;vari&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;min()&lt;span style=&#34;color: #555555&#34;&gt;-.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;,data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;vari&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color: #555555&#34;&gt;+.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;01&lt;/span&gt;),\
    np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;k_resid&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;min()&lt;span style=&#34;color: #555555&#34;&gt;-.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;,data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;k_resid&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color: #555555&#34;&gt;+.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;01&lt;/span&gt;))

pmap &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;DataFrame(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;c_[np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ones((&lt;span style=&#34;color: #336666&#34;&gt;len&lt;/span&gt;(xmesh&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ravel()),)),xmesh&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ravel(),ymesh&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ravel()])
p &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;array([])
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; pmap&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;values:
    p &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;append(p,(prob_log(line,w)))

p &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;reshape(xmesh&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;shape)

plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;contourf(xmesh, ymesh, np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;power(p,&lt;span style=&#34;color: #FF6600&#34;&gt;8&lt;/span&gt;), cmap&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;RdBu&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color: #555555&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(data1[data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;vari&amp;quot;&lt;/span&gt;],data1[data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;k_resid&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Class 0&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(data1[data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;vari&amp;quot;&lt;/span&gt;],data1[data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;k_resid&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Class 1&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;upper right&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;2-dimension logistic regression result&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/2dimension.png&#34; alt=&#34;Decision boundary for two dimensions&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;implementation&#34;&gt;Implementation&lt;/h1&gt;

&lt;h2 id=&#34;elementary-functions&#34;&gt;Elementary functions&lt;/h2&gt;

&lt;p&gt;Modularizing the code increases the readability, we define the
implementations of two mathematical functions:
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #CC00FF&#34;&gt;prob_log&lt;/span&gt;(x,w):
    &lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    probability of an observation belonging&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    to the class &amp;quot;one&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    given the predictors x and weights w&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;exp(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;dot(x,w))&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;exp(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;dot(x,w))&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #CC00FF&#34;&gt;grad_log_like&lt;/span&gt;(X, y, w):
    &lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    computes the gradient of the log-likelihood from predictors X,&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    output y and weights w&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;dot(X&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;T,y&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;apply_along_axis(&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;lambda&lt;/span&gt; x: prob_log(x,w),&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,X))&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;reshape((&lt;span style=&#34;color: #336666&#34;&gt;len&lt;/span&gt;(w),))
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;h2 id=&#34;learning-algorithm&#34;&gt;Learning algorithm&lt;/h2&gt;

&lt;p&gt;A function computes the optimal weights from iterations to find the maximal
log-likelihood of the parameters, using the two previous functions.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #CC00FF&#34;&gt;learn_weights&lt;/span&gt;(df):
    &lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    computes and updates the weights until convergence&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    given the features and outcome in a data frame&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    X &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;c_[np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ones(&lt;span style=&#34;color: #336666&#34;&gt;len&lt;/span&gt;(df)),np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;array(df&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;iloc[:,:df&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;])]
    y &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;array(df[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;])
    niter &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;
    error &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0001&lt;/span&gt;
    w &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;zeros((df&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;],))
    w0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; w&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;
    alpha &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;sum&lt;/span&gt;(&lt;span style=&#34;color: #336666&#34;&gt;abs&lt;/span&gt;(w0&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;w))&lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;&lt;/span&gt;error &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;and&lt;/span&gt; niter &lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;10000&lt;/span&gt;:
        niter&lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
        w0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; w
        w &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; w &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; alpha&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color: #336666&#34;&gt;min&lt;/span&gt;(&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,(&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;(niter&lt;span style=&#34;color: #555555&#34;&gt;**.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;))) &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; (grad_log_like(X,y,w))
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; niter&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;10000&lt;/span&gt;:
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Maximum iterations reached&amp;quot;&lt;/span&gt;)
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; w
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&#34;prediction&#34;&gt;Prediction&lt;/h2&gt;

&lt;p&gt;Once the weights have been learnt, new probabilities can be predicted from
explanatory variables.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #CC00FF&#34;&gt;predict_outcome&lt;/span&gt;(df,w):
    &lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    takes in a test data set and computed weights&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    returns a vector of predicted output, the confusion matrix&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    and the number of misclassifications&lt;/span&gt;
&lt;span style=&#34;color: #CC3300; font-style: italic&#34;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    confusion_matrix &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;zeros((&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;))
    p &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; df&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;values:
        x &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,line[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;])
        p&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;append(prob_log(x,w))
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color: #555555&#34;&gt;&amp;gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;and&lt;/span&gt; line[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;]:
            confusion_matrix[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;elif&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;and&lt;/span&gt; line[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;]:
            confusion_matrix[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;elif&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;not&lt;/span&gt; line[&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;]:
            confusion_matrix[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
        &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;else&lt;/span&gt;:
            confusion_matrix[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;return&lt;/span&gt; p, confusion_matrix, &lt;span style=&#34;color: #336666&#34;&gt;len&lt;/span&gt;(df)&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #336666&#34;&gt;sum&lt;/span&gt;(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;diag(confusion_matrix))
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&#34;cross-validated-evaluation&#34;&gt;Cross-validated evaluation&lt;/h2&gt;

&lt;p&gt;Learning weights on a training subset and getting the error on an other subset
will allow us to estimate the real error rate of our prediction. 100 cross
validations are performed and for each of them, we add the error to a list.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;error &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; []
weights &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; test &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;range&lt;/span&gt;(&lt;span style=&#34;color: #FF6600&#34;&gt;100&lt;/span&gt;):
    trainIndex &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;rand(&lt;span style=&#34;color: #336666&#34;&gt;len&lt;/span&gt;(data0)) &lt;span style=&#34;color: #555555&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #FF6600&#34;&gt;0.85&lt;/span&gt;
    data_train &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data1[trainIndex]
    data_test &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data1[&lt;span style=&#34;color: #555555&#34;&gt;~&lt;/span&gt;trainIndex]
    weights&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;append(learn_weights(data_train))
    error&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;append(predict_outcome(data_test,weights[&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;])[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The following results were obtained:
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/GLM_errors.png&#34; alt=&#34;Evolution of the model with different coefficient values&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The model produces on average 2.66 mis-classifications for 100 evaluated
banknotes. Note that on each test, 85% of the observations
went into the training set, which is arbitrary. However, too few
training points would yield inaccurate models and higher error rates.&lt;/p&gt;

&lt;h1 id=&#34;improvement-perspectives-and-conclusion&#34;&gt;Improvement perspectives and conclusion&lt;/h1&gt;

&lt;p&gt;On this data set, we managed to build independent and reliable features and
model the probability of belonging to the forged banknotes class thanks to a
logistic regression model. This appeared to be quite successful from the error
estimation on the test set. However, few further progresses could be made.&lt;/p&gt;

&lt;h2 id=&#34;testing-other-models&#34;&gt;Testing other models&lt;/h2&gt;

&lt;p&gt;We only implemented the logistic regression from scratch, given that several
models would have increased the length of this article. But some other
algorithms would have been interesting, such as:
* K nearest neighbors
* Support Vector Machine
* Model-based predictions such as naive Bayes or Quadratic Discriminant Analysis
* Classification Tree&lt;/p&gt;

&lt;p&gt;Fact of interest: the two first algorithms also build linear decision
boundaries, but based on other criteria.&lt;/p&gt;

&lt;h2 id=&#34;adjusting-the-costs&#34;&gt;Adjusting the costs&lt;/h2&gt;

&lt;p&gt;We assumed that misclassifying a true banknote was just as bad as doing so for
a forged one. This is why using a limit at p=0.5 was the optimal choice. But
suppose that taking a forged banknote for a genuine one costs twice more than
the opposite error. Then the limit probability will be set at p = 0.25 to
minimize the overall cost. More generally, a &lt;strong&gt;cost matrix&lt;/strong&gt; can be built
to minimize the sum of the element-wise product of the cost matrix with the
confusion matrix. Here is an interesting
&lt;a href=&#34;http://stackoverflow.com/questions/17464229/weka-cost-matrix-interpretation&#34; target=&#34;_blank&#34;&gt;Stack Overflow topic&lt;/a&gt;
topic on the matter.&lt;/p&gt;

&lt;h2 id=&#34;online-classification&#34;&gt;Online classification&lt;/h2&gt;

&lt;p&gt;The analysis carried on in this article is still far from the objective of some
data projects, which would be to build a reusable on-line classifier.
In our case, this could be used by bank to instantaneously verify bank notes
received. This raises some new issues like the update of different parameters
and the detection of new patterns.&lt;/p&gt;

&lt;p&gt;Special thanks to Rémi for reading the first awful drafts
and giving me some valuable feedback.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font size=&#34;0.7&#34;&gt;
 [1] Image source: scikit-learn.org
 [2] Additional resource from the University of Washington
 &lt;a href=&#34;http://courses.washington.edu/css490/2012.Winter/lecture_slides/05b_logistic_regression.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;
 [3] Resource from the Carnegie Mellon University &lt;a href=&#34;http://www.cs.cmu.edu/~awm/15781/slides/LogRegress-9-29-05.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;
&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part II</title>
      <link>https://mbesancon.github.io/post/2016-01-12-fraud-detection2/</link>
      <pubDate>Tue, 12 Jan 2016 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-01-12-fraud-detection2/</guid>
      <description>

&lt;p&gt;[1]&lt;/p&gt;

&lt;p&gt;Part II: Feature engineering&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;what-is-feature-engineering&#34;&gt;What is feature engineering?&lt;/h1&gt;

&lt;p&gt;It could be describe as the transformation of raw data to produce
a model input which will have better performance. The &lt;em&gt;features&lt;/em&gt; are
the new variables created in the process.
It is often described as based on domain knowledge and more of an
art than of a science. Therefore, it requires a great attention and
a more &amp;ldquo;manual&amp;rdquo; process than the rest of data science projects.&lt;/p&gt;

&lt;p&gt;Feature engineering tends to be heavier when raw data are far from
the expected input format of our learning models
(images or text for instance). It can be noticed that some feature
engineering was already performed on our data, since banknotes were
registered as images taken from a digital camera, and we only received
5 features for each image.&lt;/p&gt;

&lt;h1 id=&#34;correlated-variables&#34;&gt;Correlated variables&lt;/h1&gt;

&lt;h2 id=&#34;simple-linear-and-polynomial-regression&#34;&gt;Simple linear and polynomial regression&lt;/h2&gt;

&lt;p&gt;We noticed some strong dependencies between variables thanks to the
scatter plot. Those can deter the performance and robustness of
several machine learning models. Skewness and kurtosis seem to be
somehow related. A regression line can be fitted with the skewness as
explanatory variable:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;a, b &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;linregress(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;])[:&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;g+&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0.05&lt;/span&gt;) ,b&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;0.05&lt;/span&gt;),&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Simple linear regression&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Kurtosis&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/linear_reg.png&#34; alt=&#34;Linear regression&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The following result highlights a lack in the model. The slope and intercept
seem to be biased by a dense cluster of points with the skewness
between 1 and 2. The points with a low skewness are under-represented in the
model and do not follow the trend of the regression line. A robust regression
technique could correct this bias, but a polynomial regression is the most
straight-forward method to capture a higher part of the variance here.
The second-degree polynomial model can be written as:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;y_hat &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;square(x) &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;x &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; c
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and its coefficients can be determined through the minimization of least-square
error in numpy:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;a, b, c &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;),a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;c,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;2nd degree polynomial regression&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Kurtosis&amp;#39;&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;div style =&#34;text-align: center;&#34; markdown=&#34;1&#34;&gt;
![Polynomial regression](/img/posts/BankNotes/figures/poly_reg.png)
&lt;/div&gt;

&lt;p&gt;A polynomial regression yields a much better output with balanced residuals.
The p-value for all coefficients is below the 1% confidence criterion.
One strong drawback can however be noticed: the polynomial model predicts an
increase in the kurtosis for skewness superior to 2, but there is no evidence
for this statement in our data, so the model could lead to stronger errors.&lt;/p&gt;

&lt;p&gt;The regression does not capture all the variance (and does not explain all
underlying phenomena) of the Kurtosis, so a transformed variable has to be kept,
which should be independent from the skewness. The most obvious value is the
residual of the polynomial regression we performed.&lt;/p&gt;

&lt;p&gt;We can can represent this residual versus the explanatory variable
to be assured that:
* The residuals are centered around 0
* The variance of the residuals is approximately constant with the skewness
* There are still patterns in the Kurtosis: the residuals are not just noise&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;p0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;scatter(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;)
p0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;scatter(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Explanatory variable vs Regression residuals&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Residuals&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend([&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;1&amp;quot;&lt;/span&gt;])
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;div style=&#34;text-align: center;&#34; markdown=&#34;1&#34;&gt;
![Residuals of the regression](/img/posts/BankNotes/figures/resid_reg.png)
&lt;/div&gt;

&lt;p&gt;The data is now much more uncorrelated, so the feature of interest is the
residual of the regression which will replace the kurtosis in the data.&lt;/p&gt;

&lt;h2 id=&#34;class-dependent-regression&#34;&gt;Class-dependent regression&lt;/h2&gt;

&lt;p&gt;We can try and repeat the same process for the entropy and skewness, which
also seem to be related to each other.
&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;p0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;scatter(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;)
p0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;scatter(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],c&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Explanatory variable vs Regression residuals&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;Residuals&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend([&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;1&amp;quot;&lt;/span&gt;])
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 0&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Skewness&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Entropy&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/skew_entropy.png&#34; alt=&#34;Skewness-Entropy&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can try can fit a 2nd-degree polynomial function:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;ft &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 0&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;),
         ft[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;ft[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;
         np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;ft[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,linewidth&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt; ,
         label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Fitted polynom&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Skewness&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Entropy&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;bottom center&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/fit1_entropy.png&#34; alt=&#34;Polynomial regression on entropy&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, it seems that the model does not fit well our data and that the points
are not equally distributed on both side of the curve. There is another
pattern, which is class-dependent, so two polynomial curves should be fitted,
one for each class:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;f0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
x &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;14&lt;/span&gt;,&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;)
f1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)

plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(x,f0[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;x&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Fitted 0&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color: #555555&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;7&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 0&amp;quot;&lt;/span&gt;)

plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(x,f1[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;x&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Fitted 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;m+&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color: #555555&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;7&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 1&amp;quot;&lt;/span&gt;)

plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class dependent fit&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Skewness&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Entropy&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;bottom center&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class_depend.png&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/class_depend.png&#34; alt=&#34;Class-dependent polynomial regression&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The model seems to capture more of the variance in our data, which we can
confirm by plotting the residuals of the class-dependent regression.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],f0[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;
        f0[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;b+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 0&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],f1[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;
        f1[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Skewness&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Residuals&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;res_class_dep.png&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/res_class_dep.png&#34; alt=&#34;Residuals of the class-dependent polynomial regression&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We have a proper working model, with just one problem: &lt;strong&gt;we used
the class to predict the entropy&lt;/strong&gt; whereas our classification
objective is to proceed the other way around. Since we noticed
that each class follows a different curve, a difference between
the distance to the first model and the distance to the second
model, which will be noted &amp;ldquo;d&amp;rdquo;, can be computed as:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;d &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;abs(y &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;apply(f0)) &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;abs(y&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;apply(f1))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A positive &amp;ldquo;d&amp;rdquo; value indicates that the entropy of the observation
is closer to the model fitted on the class 1, this seems to be a
rather relevant indicator to use to build our models. However, this
variable seems correlated to the skewness. The latter could have become
unnecessary for our prediction, so we choose to eliminate it from
the features and take the risk of an information loss.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;d &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;abs&lt;/span&gt;(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;\
    &lt;span style=&#34;color: #336666&#34;&gt;abs&lt;/span&gt;(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])

d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; d[data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]
d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; d[data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]

plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;grid()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;b+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 0&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;],&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Class 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d vs skewness for each class&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Skewness&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/d_skew.png&#34; alt=&#34;distance vs skewness for each class&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;variable-scaling&#34;&gt;Variable scaling&lt;/h1&gt;

&lt;h2 id=&#34;common-scaling-techniques&#34;&gt;Common scaling techniques&lt;/h2&gt;

&lt;p&gt;Very different spreads could be noticed among variables during the exploratory
part. This can lead to a bias in the distance between two points. A possible
solution to this is &lt;strong&gt;scaling&lt;/strong&gt; or &lt;strong&gt;standardization&lt;/strong&gt;.
* &lt;strong&gt;Variance scaling&lt;/strong&gt; of a variable is the division of each value by the
variable standard deviation. The output is a variable with variance 1.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Min-Max standardization&lt;/strong&gt; of a variable is the division of each value by
the difference between the maximum and minimum values. The outcome values
are all contained in the interval [0,1].&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;x_stand &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;(x&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;min())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Other standardization operations exist, but those are the
most common because of the properties highlighted.&lt;/p&gt;

&lt;h2 id=&#34;advantages-and-risks&#34;&gt;Advantages and risks&lt;/h2&gt;

&lt;p&gt;Scaling variables may avoid the distance between data points
to be over-influenced by high-variance variables, because
the ability to classify the data points from a variable
is usually not proportional to the variable variance.&lt;/p&gt;

&lt;p&gt;Furthermore, all people with notions in physics and calculus
would find it awkward to compute a distance from heterogeneous
variables (which would have different units and meaning).&lt;/p&gt;

&lt;p&gt;However, scaling might increase the weight of variables carrying mostly
or only noise, to which the model would fit, increasing the error on
new data.&lt;/p&gt;

&lt;p&gt;For this case, the second risk seems very low: all variables seem to
carry information, which we could observe because of the low number of
variables.&lt;/p&gt;

&lt;h1 id=&#34;feature-engineering-pipeline&#34;&gt;Feature engineering pipeline&lt;/h1&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;a, b, c &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)

data1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;copy() &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# copying the data&lt;/span&gt;

data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;entropy&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;]
data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;k_resid&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;square(a&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]) &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; b&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt;data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; c)

data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;columns  &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;d&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# computing the feature from the entropy regression&lt;/span&gt;

f0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)
f1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;polyfit(d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;],d1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;],deg&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;)

data1[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;d&amp;quot;&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;abs&lt;/span&gt;(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;\
    &lt;span style=&#34;color: #336666&#34;&gt;abs&lt;/span&gt;(data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color: #FF6600&#34;&gt;2&lt;/span&gt;])

data1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# removing skew&lt;/span&gt;

data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;] &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;sqrt(np&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;var(data1&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;])) &lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# data normalization&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;data1&lt;/code&gt; can now be used in the next step which will consist in the
implementation of a basic machine learning algorithm. This is the key
part in an analysis-oriented data science project, and I hope to see you there.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font size=&#34;0.7&#34;&gt;
[1] Image source: Philipp Wagner: Machine Learning with OpenCV2
 &lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part I</title>
      <link>https://mbesancon.github.io/post/2016-01-11-fraud-detection/</link>
      <pubDate>Mon, 11 Jan 2016 00:00:00 -0500</pubDate>
      
      <guid>https://mbesancon.github.io/post/2016-01-11-fraud-detection/</guid>
      <description>

&lt;h2 id=&#34;a-complete-predictive-modeling-project-in-python&#34;&gt;A complete predictive modeling project in Python&lt;/h2&gt;

&lt;p&gt;Part I: Preprocessing and exploratory analysis&lt;/p&gt;

&lt;p&gt;One of the amazing things with data science is the ability to tackle
complex problems involving hidden parallel phenomena interacting with each
other, just from the data they produce.&lt;/p&gt;

&lt;p&gt;As an example, we will use data extracted from images of forged and genuine
banknotes. The distinction between the two categories would be thought to
require a deep domain expertise, which limits the ability to check
more than a few banknotes at a time. An automated and trustable test would
be of interest for many businesses, governments and organizations.&lt;/p&gt;

&lt;p&gt;Starting from the data provided by H. Dörsken and
Volker Lohweg, from the University of Applied Science of Ostwestfalen-Lippe,
Germany on the
&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/banknote+authentication&#34; target=&#34;_blank&#34;&gt;UCI Machine Learning Repository&lt;/a&gt;,
we will follow key steps of a data science project to build a performant, yet
scalable classifier.&lt;/p&gt;

&lt;p&gt;The dataset was built by applying a wavelet
transform on images of banknotes to extract 4 features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Variance, skewness, kurtosis of the wavelet transform (respectively second,
third and fourth moment of the distribution).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Entropy of the image, which can be interpreted as the amount of information
or randomness (which is represented by how different adjacent pixels are).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find further information on Wavelet on &lt;a href=&#34;https://en.wikipedia.org/wiki/Wavelet_transform&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;
or ask &lt;a href=&#34;https://www.quora.com/In-an-intuitive-explanation-what-is-a-wavelet-transform-and-how-does-it-work-in-an-image&#34; target=&#34;_blank&#34;&gt;Quora&lt;/a&gt;.
An explanation of entropy as meant in the image processing context can
be found &lt;a href=&#34;http://www.astro.cornell.edu/research/projects/compression/entropy.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To get a better understanding of the way the algorithms works,
the full model will be built from scratch or almost (not using a machine
learning library like scikit-learn on Python or caret on R).&lt;/p&gt;

&lt;p&gt;Basic statistic notions (variance, linear regression) and some basic python
knowledge is recommended to follow through the three articles.&lt;/p&gt;

&lt;h2 id=&#34;programming-choices-and-libraries&#34;&gt;Programming choices and libraries&lt;/h2&gt;

&lt;h3 id=&#34;language-and-environment&#34;&gt;Language and environment&lt;/h3&gt;

&lt;p&gt;Python, which is a great
compromise between practicality (with handy data format and manipulation)
and scalability (much easier to implement for large scale, automated
computation than R, Octave or Matlab). More precisely, Python 3.5.1 with
the Anaconda distribution 2.4.0, I personally use the Spyder environment
but feel free to keep your favorite tools.&lt;/p&gt;

&lt;h3 id=&#34;libraries&#34;&gt;Libraries&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Collections (built-in) for occurrence counting&lt;/li&gt;
&lt;li&gt;numpy 1.10.1, providing key data format, mathematical manipulation techniques.&lt;/li&gt;
&lt;li&gt;scipy 0.16.0, imported here for the distance matrix computation and the stat submodule for Quantile-Quantile plots.&lt;/li&gt;
&lt;li&gt;pandas 0.17.1 for advanced data format, high-level manipulation and visualization&lt;/li&gt;
&lt;li&gt;pyplot from matplotlib 1.5.0 for basic visualization&lt;/li&gt;
&lt;li&gt;ggplot 0.6.8, which I think is a much improved way to visualize data&lt;/li&gt;
&lt;li&gt;urllib3 to parse the data directly from the repository (no manual download)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So our first lines of code (once you placed your data in the proper repository)
should look like this:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;numpy&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;np&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;pandas&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;pd&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;ggplot&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;matplotlib&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; pyplot &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;scipy.stats&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;stats&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;scipy.spatial.distance&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;collections&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; Counter
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #00CCFF; font-weight: bold&#34;&gt;urllib3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&#34;source-files&#34;&gt;Source files&lt;/h3&gt;

&lt;p&gt;The source files will be available on the corresponding Github repository.
These include:
* preprocess.py to load the data and libraries
* exploratory.py for preliminary visualization
* feature_eng.py where the data will be transformed to boost the model performance
* model_GLM.py where we define key functions and build our model
* model.py where we will visualize characteristics of the model&lt;/p&gt;

&lt;h1 id=&#34;dataset-overview-and-exploratory-analysis&#34;&gt;Dataset overview and exploratory analysis&lt;/h1&gt;

&lt;p&gt;Understanding intuitive phenomena in the data and test its underlying structure
are the objectives for this first (usually long) phase of a data science
project, especially if you were not involved in the data collection process.&lt;/p&gt;

&lt;h2 id=&#34;data-parsing&#34;&gt;Data parsing&lt;/h2&gt;

&lt;p&gt;Instead of manually downloading the data and placing it in our project
repository, we will download using the &lt;em&gt;urllib3&lt;/em&gt; library.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;url &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt&amp;quot;&lt;/span&gt;
http &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; urllib3&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;PoolManager()
r &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; http&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;request(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;,url)
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;with&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;open&lt;/span&gt;(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;data_banknote_authentication.txt&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;as&lt;/span&gt; f:
  f&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;write(r&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;data)
r&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;release_conn()
data0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;data_banknote_authentication.txt&amp;quot;&lt;/span&gt;,
  names&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;vari&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;skew&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;kurtosis&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;entropy&amp;quot;&lt;/span&gt;,&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;])
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&#34;key-statistics-and-overview&#34;&gt;Key statistics and overview&lt;/h2&gt;

&lt;p&gt;Since the data were loaded using pandas, key methods of the DataFrame
object can be used to find some key information in the data.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;describe()
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;vari&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;skew&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;kurtosis&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;entropy&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;count&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1372.000000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;mean&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.433735&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.922353&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.397627&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-1.191657&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.444606&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;std&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.842763&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.869047&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.310030&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.101013&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.497103&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;min&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-7.042100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-13.773100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-5.286100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-8.548200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;25%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-1.773000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-1.708200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-1.574975&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-2.413450&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;50%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.496180&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.319650&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.616630&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.586650&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;75%&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.821475&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.814625&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.179250&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.394810&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;max&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.824800&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.951600&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;17.927400&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.449500&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Negative values can be noticed in the variance and entropy, whereas it is
theoretically impossible, so it can be deduced that some preprocessing
operations were already performed.&lt;/p&gt;

&lt;p&gt;We are trying to detect forged banknotes thanks to the extracted features.
The dataset contains 1372 observations, including 610 forged banknotes, so
roughly 45%. The two classes are balanced in the data, which might be relevant
for some algorithms. Indeed, a higher proportion of a category in the
characteristic of interest (here whether the banknote is genuine or not) yields
a higher &lt;strong&gt;prior probability&lt;/strong&gt; for that outcome in Bayesian reasoning.&lt;/p&gt;

&lt;h2 id=&#34;kernel-density-estimation-for-each-variable-by-class&#34;&gt;Kernel Density Estimation for each variable by class&lt;/h2&gt;

&lt;p&gt;KDE are powerful tools to understand how 1-dimensional data are distributed.
The estimate can also be split by class to find differences in the
distributions. Using ggplot and the pandas &lt;code&gt;groupby&lt;/code&gt; method, the
plots can be generated and saved as such:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;columns[:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;]:
ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ggsave(
  ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ggplot(ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;aes(x&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;v, color&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;),data&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;data0)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;
  ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;geom_density()&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;
  ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;geom_point(ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;aes(y&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;),alpha&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0.2&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;
  ggplot&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;labs(title&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;KDE &amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;v,x&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;v,y&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;KDE&amp;quot;&lt;/span&gt;),
  &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;KDE_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;v&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;.png&amp;#39;&lt;/span&gt;,width&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;18&lt;/span&gt;,height&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;12&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/KDE_entropy.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/KDE_Vari.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/KDE_skew.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/KDE_kurtosis.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Using this first simple visualization technique, we can deduce that the
variance may be much more efficient to separate the two banknotes
categories than the Kurtosis.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-variable-combinations-with-scatter-plots&#34;&gt;Visualizing variable combinations with scatter plots&lt;/h2&gt;

&lt;p&gt;We generate a color list using for-comprehension:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;col &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #336666&#34;&gt;list&lt;/span&gt;(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;if&lt;/span&gt; i&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;])
pd&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;tools&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;plotting&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;scatter_matrix(data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;ix[:,:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;],figsize&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color: #FF6600&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;3&lt;/span&gt;),
color&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;col,diagonal&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;kde&amp;#39;&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/scatter_matrix.png&#34; alt=&#34;Scatter matrix: red dots represent the class &amp;quot;1&amp;quot;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A scatter plot is the most straight-forward way to understand intuitive and
obvious patterns in the data. It is especially efficient when the number of
variables and classes is limited, such as our data set. It allows us to
understand class-dependent, non-linear relationships between variables.&lt;/p&gt;

&lt;p&gt;This is much more efficient than a simple statistic, such as the correlation
coefficient which would not have found the skewness and entropy to be related.
From these rather strong relationships between variables, we now know that
some techniques based on independent features might not be efficient here.&lt;/p&gt;

&lt;h2 id=&#34;testing-a-distribution-with-quantile-quantile-plots&#34;&gt;Testing a distribution with Quantile-Quantile plots&lt;/h2&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# Subsetting the data by class&lt;/span&gt;
d0 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data0[data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;0&lt;/span&gt;]
d1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; data0[data0[&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;]&lt;span style=&#34;color: #555555&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;1&lt;/span&gt;]

&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# For each variable&lt;/span&gt;
&lt;span style=&#34;color: #006699; font-weight: bold&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color: #000000; font-weight: bold&#34;&gt;in&lt;/span&gt; data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;columns[:&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;]:
&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;#set the figure size&lt;/span&gt;
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color: #FF6600&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;4&lt;/span&gt;))
&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# define two subplots&lt;/span&gt;
ax1 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;  plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color: #FF6600&#34;&gt;121&lt;/span&gt;)
&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# compute the quantile-quantile plot with normal distribution&lt;/span&gt;
stats&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;probplot(d0[v],dist&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;norm&amp;#39;&lt;/span&gt;,plot&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;plt)
&lt;span style=&#34;color: #0099FF; font-style: italic&#34;&gt;# add title&lt;/span&gt;
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Normal QQ-plot &amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;v &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot; - Class 0&amp;quot;&lt;/span&gt;)
ax2 &lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color: #FF6600&#34;&gt;122&lt;/span&gt;)
stats&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;probplot(d1[v],dist&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;#39;norm&amp;#39;&lt;/span&gt;,plot&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;plt)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;Normal QQ-plot &amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;v &lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot; - Class 1&amp;quot;&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;qqplot_&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;v&lt;span style=&#34;color: #555555&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;.png&amp;quot;&lt;/span&gt;,width&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;700&lt;/span&gt;,height&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #FF6600&#34;&gt;250&lt;/span&gt;)
plt&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;show()
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/qqplot_entropy.png&#34; alt=&#34;QQplot entropy&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/qqplot_skew.png&#34; alt=&#34;QQplot skewness&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/qqplot_vari.png&#34; alt=&#34;QQplot variance&#34; /&gt;
&lt;img src=&#34;https://mbesancon.github.io/img/posts/BankNotes/figures/qqplot_kurtosis.png&#34; alt=&#34;QQplot kurtosis&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Even though some variables are quite far from normally distributed, the
hypothesis would be acceptable for some model-based learning algorithms using
properties of Gaussian variables.&lt;/p&gt;

&lt;h2 id=&#34;non-parametric-distribution-with-boxplots&#34;&gt;Non-parametric distribution with boxplots&lt;/h2&gt;

&lt;p&gt;Boxplots represent the data using 25th, 50th and 75th percentiles which can be
more robust than mean and variance. The pandas library offers a quick method
and plotting tool to represent boxplots for each class and variable. It
highlights the differences in the spread of the data.&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #f0f3f3&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;data0&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color: #CC3300&#34;&gt;&amp;quot;class&amp;quot;&lt;/span&gt;)&lt;span style=&#34;color: #555555&#34;&gt;.&lt;/span&gt;boxplot(figsize&lt;span style=&#34;color: #555555&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color: #FF6600&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color: #FF6600&#34;&gt;5&lt;/span&gt;))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src=&#34;https://mbesancon.github.io/static/img/posts/BankNotes/figures/Boxplot.png&#34; alt=&#34;Boxplot representation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will be useful in the next part, when the data will be transformed to
enhance the performance and robustness of predictive models.&lt;/p&gt;

&lt;p&gt;So see you in the next part for feature engineering!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font size=&#34;0.7&#34;&gt;
[1] Image source: ik1pmr.com
&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
